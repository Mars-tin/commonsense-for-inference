{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "CommonsenseQA-submit.ipynb",
   "provenance": [],
   "collapsed_sections": [],
   "toc_visible": true
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "accelerator": "GPU",
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "krzXHFSxTZmo"
   },
   "source": [
    "# Commonsense QA: Fairseq Implementation\n",
    "\n",
    "EECS 595 Final Project, Task 1: Commonsense QA\n",
    "\n",
    "* Team ID: 2\n",
    "* Credit: Ziqiao Ma, Qingyi Chen\n",
    "* Last update: 2020.12.16\n",
    "* Validation Accuracy: 77.4%\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "maEv1O-QQrsL"
   },
   "source": [
    "CommonsenseQA is proposed by  Talmor et al. (2019). As a question answering benchmark, it presents a natural language question $Q$ of $m$ tokens $\\{q_1,q_2,\\cdots,q_m\\}$ and 5 choices $\\{a_1,a_2,\\cdots,a_5\\}$ labeled with $\\{A,B,\\cdots,E\\}$ regarding each question. Notably, the questions do not entail a inference basis in themselves, so the lack of evidence requires the model to hold a comprehensive understanding on common sense knowledge and a strong reasoning ability to make the right choice.\n",
    "\n",
    "This .ipynb aims to fine-tune the roberta model for the CommonsenseQA task based on Fairseq."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8bduHlYqRxyX"
   },
   "source": [
    "## Dependency Installation and File preparation\n",
    "\n",
    "This section installs depency such as fairseq and loads CommonsenseQA dataset."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "cSXBkaGnQwsE",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "7ea1b162-0357-436e-d034-f8de231b1099"
   },
   "source": [
    "# Use GPU during training and \n",
    "import torch\n",
    "if torch.cuda.is_available():\n",
    "    print(\"Using the GPU!\")\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Using the GPU!\n",
      "Mounted at /content/drive\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xrB13LJxMNLC"
   },
   "source": [
    "Load CommonsenseQA dataset and fairseq.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "MHL7kpD1kC_I",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "bc307b71-d0c8-4bde-9920-8a12f8c7762a"
   },
   "source": [
    "%cd /content/\n",
    "!unzip CommonsenseQA.zip"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "/content\n",
      "Archive:  CommonsenseQA.zip\n",
      "   creating: CommonsenseQA/\n",
      "  inflating: __MACOSX/._CommonsenseQA  \n",
      "  inflating: CommonsenseQA/.DS_Store  \n",
      "  inflating: __MACOSX/CommonsenseQA/._.DS_Store  \n",
      "  inflating: CommonsenseQA/finetune-arc-web-open-atomic.sh  \n",
      "  inflating: __MACOSX/CommonsenseQA/._finetune-arc-web-open-atomic.sh  \n",
      "   creating: CommonsenseQA/fairseq/\n",
      "  inflating: __MACOSX/CommonsenseQA/._fairseq  \n",
      "  inflating: CommonsenseQA/finetune.sh  \n",
      "  inflating: __MACOSX/CommonsenseQA/._finetune.sh  \n",
      "  inflating: CommonsenseQA/wrong_preds.tsv  \n",
      "  inflating: __MACOSX/CommonsenseQA/._wrong_preds.tsv  \n",
      "  inflating: CommonsenseQA/finetune-web-arc-cn.sh  \n",
      "  inflating: __MACOSX/CommonsenseQA/._finetune-web-arc-cn.sh  \n",
      "  inflating: CommonsenseQA/wrong_preds.jsonl  \n",
      "  inflating: __MACOSX/CommonsenseQA/._wrong_preds.jsonl  \n",
      "  inflating: CommonsenseQA/convert_jsonl2tsv.py  \n",
      "  inflating: __MACOSX/CommonsenseQA/._convert_jsonl2tsv.py  \n",
      "   creating: CommonsenseQA/data/\n",
      "  inflating: __MACOSX/CommonsenseQA/._data  \n",
      "  inflating: CommonsenseQA/fairseq/.DS_Store  \n",
      "  inflating: __MACOSX/CommonsenseQA/fairseq/._.DS_Store  \n",
      "   creating: CommonsenseQA/fairseq/checkpoints/\n",
      "  inflating: __MACOSX/CommonsenseQA/fairseq/._checkpoints  \n",
      "   creating: CommonsenseQA/fairseq/examples/\n",
      "  inflating: __MACOSX/CommonsenseQA/fairseq/._examples  \n",
      "  inflating: CommonsenseQA/data/.DS_Store  \n",
      "  inflating: __MACOSX/CommonsenseQA/data/._.DS_Store  \n",
      "   creating: CommonsenseQA/data/CommonsenseQA/\n",
      "  inflating: __MACOSX/CommonsenseQA/data/._CommonsenseQA  \n",
      "  inflating: CommonsenseQA/data/webchild-noun-gloss.tsv  \n",
      "  inflating: __MACOSX/CommonsenseQA/data/._webchild-noun-gloss.tsv  \n",
      "  inflating: CommonsenseQA/fairseq/checkpoints/.gitkeep  \n",
      "  inflating: __MACOSX/CommonsenseQA/fairseq/checkpoints/._.gitkeep  \n",
      "  inflating: CommonsenseQA/fairseq/examples/.DS_Store  \n",
      "  inflating: __MACOSX/CommonsenseQA/fairseq/examples/._.DS_Store  \n",
      "   creating: CommonsenseQA/fairseq/examples/roberta/\n",
      "  inflating: __MACOSX/CommonsenseQA/fairseq/examples/._roberta  \n",
      "  inflating: CommonsenseQA/data/CommonsenseQA/train.jsonl  \n",
      "  inflating: __MACOSX/CommonsenseQA/data/CommonsenseQA/._train.jsonl  \n",
      "  inflating: CommonsenseQA/data/CommonsenseQA/test.jsonl  \n",
      "  inflating: __MACOSX/CommonsenseQA/data/CommonsenseQA/._test.jsonl  \n",
      "  inflating: CommonsenseQA/data/CommonsenseQA/valid.jsonl  \n",
      "  inflating: __MACOSX/CommonsenseQA/data/CommonsenseQA/._valid.jsonl  \n",
      "  inflating: CommonsenseQA/data/CommonsenseQA/valid-propn.jsonl  \n",
      "  inflating: __MACOSX/CommonsenseQA/data/CommonsenseQA/._valid-propn.jsonl  \n",
      "  inflating: CommonsenseQA/data/CommonsenseQA/dict.txt  \n",
      "  inflating: __MACOSX/CommonsenseQA/data/CommonsenseQA/._dict.txt  \n",
      "   creating: CommonsenseQA/fairseq/examples/roberta/commonsense_qa_with_kb_task/\n",
      "  inflating: __MACOSX/CommonsenseQA/fairseq/examples/roberta/._commonsense_qa_with_kb_task  \n",
      "   creating: CommonsenseQA/fairseq/examples/roberta/commonsense_qa/\n",
      "  inflating: __MACOSX/CommonsenseQA/fairseq/examples/roberta/._commonsense_qa  \n",
      "  inflating: CommonsenseQA/fairseq/examples/roberta/commonsense_qa_with_kb_task/__init__.py  \n",
      "  inflating: __MACOSX/CommonsenseQA/fairseq/examples/roberta/commonsense_qa_with_kb_task/.___init__.py  \n",
      "  inflating: CommonsenseQA/fairseq/examples/roberta/commonsense_qa_with_kb_task/commonsense_qa_with_kb_task.py  \n",
      "  inflating: __MACOSX/CommonsenseQA/fairseq/examples/roberta/commonsense_qa_with_kb_task/._commonsense_qa_with_kb_task.py  \n",
      "  inflating: CommonsenseQA/fairseq/examples/roberta/commonsense_qa/__init__.py  \n",
      "  inflating: __MACOSX/CommonsenseQA/fairseq/examples/roberta/commonsense_qa/.___init__.py  \n",
      "  inflating: CommonsenseQA/fairseq/examples/roberta/commonsense_qa/download_cqa_data.sh  \n",
      "  inflating: __MACOSX/CommonsenseQA/fairseq/examples/roberta/commonsense_qa/._download_cqa_data.sh  \n",
      "  inflating: CommonsenseQA/fairseq/examples/roberta/commonsense_qa/README.md  \n",
      "  inflating: __MACOSX/CommonsenseQA/fairseq/examples/roberta/commonsense_qa/._README.md  \n",
      "  inflating: CommonsenseQA/fairseq/examples/roberta/commonsense_qa/commonsense_qa_task.py  \n",
      "  inflating: __MACOSX/CommonsenseQA/fairseq/examples/roberta/commonsense_qa/._commonsense_qa_task.py  \n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "E2NeA14_hteN",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "2a794914-b68a-46b1-f72e-1fef64cbcb19"
   },
   "source": [
    "!pip install fairseq"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Collecting fairseq\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2c/da/7c7032988dade3b21ccfd5b226e50b382abfd3459129d67240bb004506ae/fairseq-0.10.1-cp36-cp36m-manylinux1_x86_64.whl (1.7MB)\n",
      "\u001b[K     |████████████████████████████████| 1.7MB 12.8MB/s \n",
      "\u001b[?25hRequirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from fairseq) (0.8)\n",
      "Requirement already satisfied: cython in /usr/local/lib/python3.6/dist-packages (from fairseq) (0.29.21)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from fairseq) (4.41.1)\n",
      "Collecting hydra-core\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f0/1f/7f502b9e37596164111655861370b08626f46f9e4524433c354f472765d4/hydra_core-1.0.4-py3-none-any.whl (122kB)\n",
      "\u001b[K     |████████████████████████████████| 122kB 60.0MB/s \n",
      "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from fairseq) (1.18.5)\n",
      "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from fairseq) (2019.12.20)\n",
      "Requirement already satisfied: cffi in /usr/local/lib/python3.6/dist-packages (from fairseq) (1.14.4)\n",
      "Collecting sacrebleu>=1.4.12\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/c4/8e948f601a4f9609e8b2b58f31966cb13cf17b940b82aa3e767f01c42c52/sacrebleu-1.4.14-py3-none-any.whl (64kB)\n",
      "\u001b[K     |████████████████████████████████| 71kB 7.4MB/s \n",
      "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from fairseq) (1.7.0+cu101)\n",
      "Collecting antlr4-python3-runtime==4.8\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/56/02/789a0bddf9c9b31b14c3e79ec22b9656185a803dc31c15f006f9855ece0d/antlr4-python3-runtime-4.8.tar.gz (112kB)\n",
      "\u001b[K     |████████████████████████████████| 112kB 61.7MB/s \n",
      "\u001b[?25hCollecting omegaconf>=2.0.5\n",
      "  Downloading https://files.pythonhosted.org/packages/e5/f6/043b6d255dd6fbf2025110cea35b87f4c5100a181681d8eab496269f0d5b/omegaconf-2.0.5-py3-none-any.whl\n",
      "Requirement already satisfied: importlib-resources; python_version < \"3.9\" in /usr/local/lib/python3.6/dist-packages (from hydra-core->fairseq) (3.3.0)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.6/dist-packages (from cffi->fairseq) (2.20)\n",
      "Collecting portalocker\n",
      "  Downloading https://files.pythonhosted.org/packages/89/a6/3814b7107e0788040870e8825eebf214d72166adf656ba7d4bf14759a06a/portalocker-2.0.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch->fairseq) (3.7.4.3)\n",
      "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch->fairseq) (0.16.0)\n",
      "Collecting PyYAML>=5.1.*\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/64/c2/b80047c7ac2478f9501676c988a5411ed5572f35d1beff9cae07d321512c/PyYAML-5.3.1.tar.gz (269kB)\n",
      "\u001b[K     |████████████████████████████████| 276kB 57.8MB/s \n",
      "\u001b[?25hRequirement already satisfied: zipp>=0.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-resources; python_version < \"3.9\"->hydra-core->fairseq) (3.4.0)\n",
      "Building wheels for collected packages: antlr4-python3-runtime, PyYAML\n",
      "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.8-cp36-none-any.whl size=141231 sha256=2d664fc0f620425ee8258c543f7e2badef9c55786a747b751d247922a00e1423\n",
      "  Stored in directory: /root/.cache/pip/wheels/e3/e2/fa/b78480b448b8579ddf393bebd3f47ee23aa84c89b6a78285c8\n",
      "  Building wheel for PyYAML (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for PyYAML: filename=PyYAML-5.3.1-cp36-cp36m-linux_x86_64.whl size=44620 sha256=36052501be5420fd12a5313e543ebcb1bb801654cd7de4d7add1b76cd568496f\n",
      "  Stored in directory: /root/.cache/pip/wheels/a7/c1/ea/cf5bd31012e735dc1dfea3131a2d5eae7978b251083d6247bd\n",
      "Successfully built antlr4-python3-runtime PyYAML\n",
      "Installing collected packages: antlr4-python3-runtime, PyYAML, omegaconf, hydra-core, portalocker, sacrebleu, fairseq\n",
      "  Found existing installation: PyYAML 3.13\n",
      "    Uninstalling PyYAML-3.13:\n",
      "      Successfully uninstalled PyYAML-3.13\n",
      "Successfully installed PyYAML-5.3.1 antlr4-python3-runtime-4.8 fairseq-0.10.1 hydra-core-1.0.4 omegaconf-2.0.5 portalocker-2.0.0 sacrebleu-1.4.14\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ufZjX8xlMwUb"
   },
   "source": [
    "Load Roberta."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "2Fj7klcpl6-3",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "2232771d-ca67-4b90-870d-1eda6bfab068"
   },
   "source": [
    "# Download roberta model\n",
    "!wget -O roberta.large.tar.gz https://dl.fbaipublicfiles.com/fairseq/models/roberta.large.tar.gz\n",
    "!tar -xvzf roberta.large.tar.gz"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "--2020-12-14 03:06:49--  https://dl.fbaipublicfiles.com/fairseq/models/roberta.large.tar.gz\n",
      "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 104.22.74.142, 172.67.9.4, 104.22.75.142, ...\n",
      "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|104.22.74.142|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 655283069 (625M) [application/gzip]\n",
      "Saving to: ‘roberta.large.tar.gz’\n",
      "\n",
      "roberta.large.tar.g 100%[===================>] 624.93M  23.5MB/s    in 27s     \n",
      "\n",
      "2020-12-14 03:07:17 (23.1 MB/s) - ‘roberta.large.tar.gz’ saved [655283069/655283069]\n",
      "\n",
      "roberta.large/\n",
      "roberta.large/dict.txt\n",
      "roberta.large/model.pt\n",
      "roberta.large/NOTE\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1B6InDsvKHKz"
   },
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KCLAYjVeYHle"
   },
   "source": [
    "This section prepares the data and arguments for training."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "okuxVwtmOK22",
    "outputId": "4bcb41bf-e757-4b99-c49b-9a59ded07815"
   },
   "source": [
    "%cd /content/CommonsenseQA/"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "/content/CommonsenseQA\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6FMj2Q1tUx5U"
   },
   "source": [
    "Compose the arguments for training."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "fN46aEMAmPii",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "8ce50350-1229-4efe-c14c-6e4f80bd621f"
   },
   "source": [
    "%%writefile finetune.sh\n",
    "#!/bin/bash\n",
    "\n",
    "## Write the finetuning part to a bash script file\n",
    "# Modified following from the original script to get it to run on Google AI platform and Colab\n",
    "# - Set MAX_SENTENCES=8\n",
    "# - Added --update-freq 4\n",
    "\n",
    "MAX_UPDATES=3000      # Number of training steps.\n",
    "WARMUP_UPDATES=150    # Linearly increase LR over this many steps.\n",
    "LR=1e-05              # Peak LR for polynomial LR scheduler.\n",
    "MAX_SENTENCES=8      # Batch size.\n",
    "SEED=23                # Random seed.\n",
    "\n",
    "BASEDIR=/content\n",
    "CQA_PATH=$BASEDIR/CommonsenseQA \n",
    "ROBERTA_PATH=${BASEDIR}/roberta.large/model.pt\n",
    "DATA_DIR=${CQA_PATH}/data/CommonsenseQA\n",
    "\n",
    "# we use the --user-dir option to load the task from\n",
    "# the examples/roberta/commonsense_qa directory:\n",
    "FAIRSEQ_PATH=${CQA_PATH}/fairseq\n",
    "FAIRSEQ_USER_DIR=${FAIRSEQ_PATH}/examples/roberta/commonsense_qa\n",
    "\n",
    "cd $FAIRSEQ_PATH\n",
    "CUDA_VISIBLE_DEVICES=0 fairseq-train --fp16 --ddp-backend=no_c10d \\\n",
    "    $DATA_DIR \\\n",
    "    --update-freq 4 \\\n",
    "    --save-dir ./checkpoints \\\n",
    "    --user-dir $FAIRSEQ_USER_DIR \\\n",
    "    --restore-file $ROBERTA_PATH \\\n",
    "    --reset-optimizer --reset-dataloader --reset-meters \\\n",
    "    --no-epoch-checkpoints --no-last-checkpoints --no-save-optimizer-state \\\n",
    "    --best-checkpoint-metric accuracy --maximize-best-checkpoint-metric \\\n",
    "    --task commonsense_qa --init-token 0 --bpe gpt2 \\\n",
    "    --arch roberta_large --max-positions 512 \\\n",
    "    --dropout 0.1 --attention-dropout 0.1 --weight-decay 0.01 \\\n",
    "    --criterion sentence_ranking --num-classes 5 \\\n",
    "    --optimizer adam --adam-betas '(0.9, 0.98)' --adam-eps 1e-06 --clip-norm 0.0 \\\n",
    "    --lr-scheduler polynomial_decay --lr $LR \\\n",
    "    --warmup-updates $WARMUP_UPDATES --total-num-update $MAX_UPDATES \\\n",
    "    --batch-size $MAX_SENTENCES \\\n",
    "    --max-update $MAX_UPDATES \\\n",
    "    --log-format simple --log-interval 25 \\\n",
    "    --seed $SEED"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Overwriting finetune.sh\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2FMXS3M-VFVE"
   },
   "source": [
    "## Training..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xkwcOmtYYNFx"
   },
   "source": [
    "This section trains the model."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "EfEfAzQ_mV-z",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "a593a9f9-0e72-4caa-b2f7-333293166cdc"
   },
   "source": [
    "!bash finetune.sh"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "2020-12-14 03:22:47 | INFO | fairseq_cli.train | Namespace(activation_dropout=0.0, activation_fn='gelu', adam_betas='(0.9, 0.98)', adam_eps=1e-06, all_gather_list_size=16384, arch='roberta_large', attention_dropout=0.1, batch_size=8, batch_size_valid=8, best_checkpoint_metric='accuracy', bf16=False, bpe='gpt2', broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=0.0, cpu=False, criterion='sentence_ranking', curriculum=0, data='/content/CommonsenseQA/data/CommonsenseQA', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=1, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', dropout=0.1, empty_cache_freq=0, encoder_attention_heads=16, encoder_embed_dim=1024, encoder_ffn_embed_dim=4096, encoder_layerdrop=0, encoder_layers=24, encoder_layers_to_keep=None, end_learning_rate=0.0, fast_stat_sync=False, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, force_anneal=None, fp16=True, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='test', gpt2_encoder_json='https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', gpt2_vocab_bpe='https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe', init_token=0, keep_best_checkpoints=-1, keep_interval_updates=-1, keep_last_epochs=-1, localsgd_frequency=3, log_format='simple', log_interval=25, lr=[1e-05], lr_scheduler='polynomial_decay', max_epoch=0, max_positions=512, max_tokens=None, max_tokens_valid=None, max_update=3000, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, min_lr=-1.0, model_parallel_size=1, no_epoch_checkpoints=True, no_last_checkpoints=True, no_progress_bar=False, no_save=False, no_save_optimizer_state=True, no_seed_provided=False, nprocs_per_node=1, num_classes=5, num_shards=1, num_workers=1, optimizer='adam', optimizer_overrides='{}', patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, pooler_activation_fn='tanh', pooler_dropout=0.0, power=1.0, profile=False, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, ranking_head_name='sentence_classification_head', required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, restore_file='/content/roberta.large/model.pt', save_dir='./checkpoints', save_interval=1, save_interval_updates=0, save_predictions=None, scoring='bleu', seed=23, sentence_avg=False, shard_id=0, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, spectral_norm_classification_head=False, stop_time_hours=0, task='commonsense_qa', tensorboard_logdir=None, threshold_loss_scale=None, tokenizer=None, total_num_update=3000, tpu=False, train_subset='train', update_freq=[4], use_bmuf=False, use_old_adam=False, user_dir='/content/CommonsenseQA/fairseq/examples/roberta/commonsense_qa', valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, warmup_updates=150, weight_decay=0.01, zero_sharding='none')\n",
      "| dictionary: 50265 types\n",
      "2020-12-14 03:22:47 | INFO | fairseq.file_utils | https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json not found in cache, downloading to /tmp/tmp_uihxgcb\n",
      "1042301B [00:00, 1950086.47B/s]\n",
      "2020-12-14 03:22:48 | INFO | fairseq.file_utils | copying /tmp/tmp_uihxgcb to cache at /root/.cache/torch/pytorch_fairseq/e2aab4d600e7568c2d88fc7732130ccc815ea84ec63906cb0913c7a3a4906a2e.0f323dfaed92d080380e63f0291d0f31adfa8c61a62cbcb3cb8114f061be27f7\n",
      "2020-12-14 03:22:48 | INFO | fairseq.file_utils | creating metadata file for /root/.cache/torch/pytorch_fairseq/e2aab4d600e7568c2d88fc7732130ccc815ea84ec63906cb0913c7a3a4906a2e.0f323dfaed92d080380e63f0291d0f31adfa8c61a62cbcb3cb8114f061be27f7\n",
      "2020-12-14 03:22:48 | INFO | fairseq.file_utils | removing temp file /tmp/tmp_uihxgcb\n",
      "2020-12-14 03:22:48 | INFO | fairseq.file_utils | https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe not found in cache, downloading to /tmp/tmpuus_gwan\n",
      "456318B [00:00, 1331039.58B/s]\n",
      "2020-12-14 03:22:49 | INFO | fairseq.file_utils | copying /tmp/tmpuus_gwan to cache at /root/.cache/torch/pytorch_fairseq/b04a6d337c09f464fe8f0df1d3524db88a597007d63f05d97e437f65840cdba5.939bed25cbdab15712bac084ee713d6c78e221c5156c68cb0076b03f5170600f\n",
      "2020-12-14 03:22:49 | INFO | fairseq.file_utils | creating metadata file for /root/.cache/torch/pytorch_fairseq/b04a6d337c09f464fe8f0df1d3524db88a597007d63f05d97e437f65840cdba5.939bed25cbdab15712bac084ee713d6c78e221c5156c68cb0076b03f5170600f\n",
      "2020-12-14 03:22:49 | INFO | fairseq.file_utils | removing temp file /tmp/tmpuus_gwan\n",
      "| Loaded valid with 1221 samples\n",
      "2020-12-14 03:23:02 | INFO | fairseq_cli.train | RobertaModel(\n",
      "  (encoder): RobertaEncoder(\n",
      "    (sentence_encoder): TransformerSentenceEncoder(\n",
      "      (dropout_module): FairseqDropout()\n",
      "      (embed_tokens): Embedding(50265, 1024, padding_idx=1)\n",
      "      (embed_positions): LearnedPositionalEmbedding(514, 1024, padding_idx=1)\n",
      "      (layers): ModuleList(\n",
      "        (0): TransformerSentenceEncoderLayer(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (activation_dropout_module): FairseqDropout()\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (dropout_module): FairseqDropout()\n",
      "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (1): TransformerSentenceEncoderLayer(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (activation_dropout_module): FairseqDropout()\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (dropout_module): FairseqDropout()\n",
      "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (2): TransformerSentenceEncoderLayer(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (activation_dropout_module): FairseqDropout()\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (dropout_module): FairseqDropout()\n",
      "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (3): TransformerSentenceEncoderLayer(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (activation_dropout_module): FairseqDropout()\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (dropout_module): FairseqDropout()\n",
      "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (4): TransformerSentenceEncoderLayer(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (activation_dropout_module): FairseqDropout()\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (dropout_module): FairseqDropout()\n",
      "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (5): TransformerSentenceEncoderLayer(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (activation_dropout_module): FairseqDropout()\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (dropout_module): FairseqDropout()\n",
      "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (6): TransformerSentenceEncoderLayer(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (activation_dropout_module): FairseqDropout()\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (dropout_module): FairseqDropout()\n",
      "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (7): TransformerSentenceEncoderLayer(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (activation_dropout_module): FairseqDropout()\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (dropout_module): FairseqDropout()\n",
      "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (8): TransformerSentenceEncoderLayer(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (activation_dropout_module): FairseqDropout()\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (dropout_module): FairseqDropout()\n",
      "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (9): TransformerSentenceEncoderLayer(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (activation_dropout_module): FairseqDropout()\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (dropout_module): FairseqDropout()\n",
      "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (10): TransformerSentenceEncoderLayer(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (activation_dropout_module): FairseqDropout()\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (dropout_module): FairseqDropout()\n",
      "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (11): TransformerSentenceEncoderLayer(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (activation_dropout_module): FairseqDropout()\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (dropout_module): FairseqDropout()\n",
      "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (12): TransformerSentenceEncoderLayer(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (activation_dropout_module): FairseqDropout()\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (dropout_module): FairseqDropout()\n",
      "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (13): TransformerSentenceEncoderLayer(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (activation_dropout_module): FairseqDropout()\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (dropout_module): FairseqDropout()\n",
      "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (14): TransformerSentenceEncoderLayer(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (activation_dropout_module): FairseqDropout()\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (dropout_module): FairseqDropout()\n",
      "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (15): TransformerSentenceEncoderLayer(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (activation_dropout_module): FairseqDropout()\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (dropout_module): FairseqDropout()\n",
      "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (16): TransformerSentenceEncoderLayer(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (activation_dropout_module): FairseqDropout()\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (dropout_module): FairseqDropout()\n",
      "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (17): TransformerSentenceEncoderLayer(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (activation_dropout_module): FairseqDropout()\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (dropout_module): FairseqDropout()\n",
      "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (18): TransformerSentenceEncoderLayer(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (activation_dropout_module): FairseqDropout()\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (dropout_module): FairseqDropout()\n",
      "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (19): TransformerSentenceEncoderLayer(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (activation_dropout_module): FairseqDropout()\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (dropout_module): FairseqDropout()\n",
      "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (20): TransformerSentenceEncoderLayer(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (activation_dropout_module): FairseqDropout()\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (dropout_module): FairseqDropout()\n",
      "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (21): TransformerSentenceEncoderLayer(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (activation_dropout_module): FairseqDropout()\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (dropout_module): FairseqDropout()\n",
      "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (22): TransformerSentenceEncoderLayer(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (activation_dropout_module): FairseqDropout()\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (dropout_module): FairseqDropout()\n",
      "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (23): TransformerSentenceEncoderLayer(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (activation_dropout_module): FairseqDropout()\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (dropout_module): FairseqDropout()\n",
      "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "      (emb_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (lm_head): RobertaLMHead(\n",
      "      (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "  )\n",
      "  (classification_heads): ModuleDict(\n",
      "    (sentence_classification_head): RobertaClassificationHead(\n",
      "      (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (dropout): Dropout(p=0.0, inplace=False)\n",
      "      (out_proj): Linear(in_features=1024, out_features=1, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "2020-12-14 03:23:02 | INFO | fairseq_cli.train | task: commonsense_qa (CommonsenseQATask)\n",
      "2020-12-14 03:23:02 | INFO | fairseq_cli.train | model: roberta_large (RobertaModel)\n",
      "2020-12-14 03:23:02 | INFO | fairseq_cli.train | criterion: sentence_ranking (SentenceRankingCriterion)\n",
      "2020-12-14 03:23:02 | INFO | fairseq_cli.train | num. model params: 356461658 (num. trained: 356461658)\n",
      "2020-12-14 03:23:13 | INFO | fairseq.trainer | detected shared parameter: encoder.sentence_encoder.embed_tokens.weight <- encoder.lm_head.weight\n",
      "2020-12-14 03:23:13 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************\n",
      "2020-12-14 03:23:13 | INFO | fairseq.utils | rank   0: capabilities =  7.5  ; total memory = 14.726 GB ; name = Tesla T4                                \n",
      "2020-12-14 03:23:13 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************\n",
      "2020-12-14 03:23:13 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)\n",
      "2020-12-14 03:23:13 | INFO | fairseq_cli.train | max tokens per GPU = None and max sentences per GPU = 8\n",
      "2020-12-14 03:23:13 | INFO | fairseq.models.roberta.model | Overwriting classification_heads.sentence_classification_head.dense.weight\n",
      "2020-12-14 03:23:13 | INFO | fairseq.models.roberta.model | Overwriting classification_heads.sentence_classification_head.dense.bias\n",
      "2020-12-14 03:23:13 | INFO | fairseq.models.roberta.model | Overwriting classification_heads.sentence_classification_head.out_proj.weight\n",
      "2020-12-14 03:23:13 | INFO | fairseq.models.roberta.model | Overwriting classification_heads.sentence_classification_head.out_proj.bias\n",
      "2020-12-14 03:23:13 | INFO | fairseq.trainer | loaded checkpoint /content/roberta.large/model.pt (epoch 1 @ 0 updates)\n",
      "2020-12-14 03:23:13 | INFO | fairseq.trainer | loading train data for epoch 1\n",
      "| Loaded train with 9741 samples\n",
      "2020-12-14 03:23:21 | INFO | fairseq.trainer | begin training epoch 1\n",
      "2020-12-14 03:23:58 | INFO | train_inner | epoch 001:     25 / 305 loss=2.321, nll_loss=0.096, accuracy=21.8, wps=525.9, ups=0.68, wpb=775.3, bsz=32, num_updates=25, lr=1.66667e-06, gnorm=5.143, loss_scale=128, train_wall=37, wall=45\n",
      "2020-12-14 03:24:35 | INFO | train_inner | epoch 001:     50 / 305 loss=2.321, nll_loss=0.098, accuracy=22.9, wps=513.3, ups=0.67, wpb=761.7, bsz=32, num_updates=50, lr=3.33333e-06, gnorm=7.288, loss_scale=128, train_wall=37, wall=82\n",
      "2020-12-14 03:25:13 | INFO | train_inner | epoch 001:     75 / 305 loss=2.318, nll_loss=0.096, accuracy=22.2, wps=517.4, ups=0.67, wpb=775, bsz=32, num_updates=75, lr=5e-06, gnorm=10.521, loss_scale=128, train_wall=37, wall=120\n",
      "2020-12-14 03:25:51 | INFO | train_inner | epoch 001:    100 / 305 loss=2.311, nll_loss=0.097, accuracy=29.8, wps=502.9, ups=0.66, wpb=766.2, bsz=32, num_updates=100, lr=6.66667e-06, gnorm=6.09, loss_scale=128, train_wall=38, wall=158\n",
      "2020-12-14 03:26:29 | INFO | train_inner | epoch 001:    125 / 305 loss=2.248, nll_loss=0.093, accuracy=32, wps=507.8, ups=0.66, wpb=774.8, bsz=32, num_updates=125, lr=8.33333e-06, gnorm=21.981, loss_scale=128, train_wall=38, wall=196\n",
      "2020-12-14 03:27:07 | INFO | train_inner | epoch 001:    150 / 305 loss=2.078, nll_loss=0.085, accuracy=41.2, wps=506.9, ups=0.65, wpb=778.1, bsz=32, num_updates=150, lr=1e-05, gnorm=49.123, loss_scale=128, train_wall=38, wall=234\n",
      "2020-12-14 03:27:45 | INFO | train_inner | epoch 001:    175 / 305 loss=1.913, nll_loss=0.079, accuracy=46, wps=507.9, ups=0.66, wpb=768.7, bsz=31.9, num_updates=175, lr=9.91228e-06, gnorm=40.595, loss_scale=128, train_wall=38, wall=272\n",
      "2020-12-14 03:28:00 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 64.0\n",
      "2020-12-14 03:28:10 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 32.0\n",
      "2020-12-14 03:28:26 | INFO | train_inner | epoch 001:    202 / 305 loss=1.66, nll_loss=0.069, accuracy=53.4, wps=474.6, ups=0.61, wpb=773.8, bsz=32, num_updates=200, lr=9.82456e-06, gnorm=51.431, loss_scale=32, train_wall=41, wall=313\n",
      "2020-12-14 03:28:44 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16.0\n",
      "2020-12-14 03:29:06 | INFO | train_inner | epoch 001:    228 / 305 loss=1.677, nll_loss=0.069, accuracy=54.1, wps=491.2, ups=0.63, wpb=779.1, bsz=32, num_updates=225, lr=9.73684e-06, gnorm=112.503, loss_scale=16, train_wall=40, wall=353\n",
      "2020-12-14 03:29:44 | INFO | train_inner | epoch 001:    253 / 305 loss=1.689, nll_loss=0.07, accuracy=52.8, wps=505.8, ups=0.65, wpb=774.4, bsz=32, num_updates=250, lr=9.64912e-06, gnorm=133.745, loss_scale=16, train_wall=38, wall=391\n",
      "2020-12-14 03:30:22 | INFO | train_inner | epoch 001:    278 / 305 loss=1.561, nll_loss=0.065, accuracy=57.1, wps=505.5, ups=0.66, wpb=769, bsz=32, num_updates=275, lr=9.5614e-06, gnorm=59.742, loss_scale=16, train_wall=38, wall=429\n",
      "2020-12-14 03:30:25 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8.0\n",
      "2020-12-14 03:31:01 | INFO | train_inner | epoch 001:    304 / 305 loss=1.486, nll_loss=0.062, accuracy=57.8, wps=488, ups=0.63, wpb=771.5, bsz=32, num_updates=300, lr=9.47368e-06, gnorm=82.85, loss_scale=8, train_wall=39, wall=468\n",
      "2020-12-14 03:31:02 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "2020-12-14 03:31:20 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 1.239 | nll_loss 0.052 | accuracy 68.4 | wps 1694 | wpb 191 | bsz 8 | num_updates 301\n",
      "2020-12-14 03:31:20 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2020-12-14 03:31:29 | INFO | fairseq.checkpoint_utils | saved checkpoint ./checkpoints/checkpoint_best.pt (epoch 1 @ 301 updates, score 68.4) (writing took 9.316540148000058 seconds)\n",
      "2020-12-14 03:31:29 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)\n",
      "2020-12-14 03:31:29 | INFO | train | epoch 001 | loss 1.965 | nll_loss 0.081 | accuracy 40.9 | wps 475.8 | ups 0.62 | wpb 771 | bsz 31.9 | num_updates 301 | lr 9.47018e-06 | gnorm 48.472 | loss_scale 8 | train_wall 461 | wall 496\n",
      "2020-12-14 03:31:29 | INFO | fairseq.trainer | begin training epoch 2\n",
      "2020-12-14 03:32:06 | INFO | train_inner | epoch 002:     24 / 305 loss=1.389, nll_loss=0.058, accuracy=61.9, wps=293, ups=0.39, wpb=753, bsz=31.4, num_updates=325, lr=9.38596e-06, gnorm=78.371, loss_scale=8, train_wall=37, wall=533\n",
      "2020-12-14 03:32:43 | INFO | train_inner | epoch 002:     49 / 305 loss=1.296, nll_loss=0.054, accuracy=66.5, wps=511.7, ups=0.66, wpb=773.4, bsz=32, num_updates=350, lr=9.29825e-06, gnorm=67.704, loss_scale=8, train_wall=38, wall=570\n",
      "2020-12-14 03:33:21 | INFO | train_inner | epoch 002:     74 / 305 loss=1.2, nll_loss=0.051, accuracy=66, wps=504.1, ups=0.67, wpb=755.8, bsz=32, num_updates=375, lr=9.21053e-06, gnorm=35.336, loss_scale=8, train_wall=37, wall=608\n",
      "2020-12-14 03:33:59 | INFO | train_inner | epoch 002:     99 / 305 loss=1.296, nll_loss=0.053, accuracy=64.2, wps=509.9, ups=0.65, wpb=786.1, bsz=32, num_updates=400, lr=9.12281e-06, gnorm=32.403, loss_scale=8, train_wall=38, wall=647\n",
      "2020-12-14 03:34:37 | INFO | train_inner | epoch 002:    124 / 305 loss=1.225, nll_loss=0.051, accuracy=65.8, wps=506.7, ups=0.66, wpb=766.2, bsz=32, num_updates=425, lr=9.03509e-06, gnorm=37.519, loss_scale=8, train_wall=38, wall=684\n",
      "2020-12-14 03:35:15 | INFO | train_inner | epoch 002:    149 / 305 loss=1.216, nll_loss=0.051, accuracy=67.8, wps=502.8, ups=0.66, wpb=764.5, bsz=32, num_updates=450, lr=8.94737e-06, gnorm=48.974, loss_scale=8, train_wall=38, wall=722\n",
      "2020-12-14 03:35:54 | INFO | train_inner | epoch 002:    174 / 305 loss=1.207, nll_loss=0.049, accuracy=66.9, wps=509.2, ups=0.65, wpb=785.5, bsz=32, num_updates=475, lr=8.85965e-06, gnorm=76.456, loss_scale=8, train_wall=38, wall=761\n",
      "2020-12-14 03:36:32 | INFO | train_inner | epoch 002:    199 / 305 loss=1.24, nll_loss=0.051, accuracy=67.4, wps=508.5, ups=0.65, wpb=778.6, bsz=32, num_updates=500, lr=8.77193e-06, gnorm=31.835, loss_scale=8, train_wall=38, wall=799\n",
      "2020-12-14 03:37:10 | INFO | train_inner | epoch 002:    224 / 305 loss=1.19, nll_loss=0.05, accuracy=67.8, wps=501.7, ups=0.66, wpb=761.7, bsz=31.9, num_updates=525, lr=8.68421e-06, gnorm=32.101, loss_scale=8, train_wall=38, wall=837\n",
      "2020-12-14 03:37:48 | INFO | train_inner | epoch 002:    249 / 305 loss=1.238, nll_loss=0.051, accuracy=67, wps=508.9, ups=0.65, wpb=782.2, bsz=32, num_updates=550, lr=8.59649e-06, gnorm=36.405, loss_scale=8, train_wall=38, wall=876\n",
      "2020-12-14 03:38:26 | INFO | train_inner | epoch 002:    274 / 305 loss=1.146, nll_loss=0.048, accuracy=68.4, wps=508.9, ups=0.66, wpb=768.1, bsz=32, num_updates=575, lr=8.50877e-06, gnorm=43.928, loss_scale=8, train_wall=38, wall=913\n",
      "2020-12-14 03:39:04 | INFO | train_inner | epoch 002:    299 / 305 loss=1.174, nll_loss=0.049, accuracy=69.8, wps=505.5, ups=0.66, wpb=767.4, bsz=32, num_updates=600, lr=8.42105e-06, gnorm=29.379, loss_scale=8, train_wall=38, wall=951\n",
      "2020-12-14 03:39:13 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "2020-12-14 03:39:30 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 0.906 | nll_loss 0.038 | accuracy 75.9 | wps 1687.6 | wpb 191 | bsz 8 | num_updates 606 | best_accuracy 75.9\n",
      "2020-12-14 03:39:30 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2020-12-14 03:39:40 | INFO | fairseq.checkpoint_utils | saved checkpoint ./checkpoints/checkpoint_best.pt (epoch 2 @ 606 updates, score 75.9) (writing took 9.21432443599997 seconds)\n",
      "2020-12-14 03:39:40 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)\n",
      "2020-12-14 03:39:40 | INFO | train | epoch 002 | loss 1.23 | nll_loss 0.051 | accuracy 66.7 | wps 479 | ups 0.62 | wpb 770.6 | bsz 31.9 | num_updates 606 | lr 8.4e-06 | gnorm 45.498 | loss_scale 8 | train_wall 463 | wall 987\n",
      "2020-12-14 03:39:40 | INFO | fairseq.trainer | begin training epoch 3\n",
      "2020-12-14 03:40:09 | INFO | train_inner | epoch 003:     19 / 305 loss=0.951, nll_loss=0.039, accuracy=73.6, wps=295.5, ups=0.39, wpb=764.9, bsz=31.4, num_updates=625, lr=8.33333e-06, gnorm=30.243, loss_scale=8, train_wall=38, wall=1016\n",
      "2020-12-14 03:40:47 | INFO | train_inner | epoch 003:     44 / 305 loss=0.967, nll_loss=0.04, accuracy=73.7, wps=508.3, ups=0.66, wpb=771.2, bsz=31.9, num_updates=650, lr=8.24561e-06, gnorm=33.671, loss_scale=8, train_wall=38, wall=1054\n",
      "2020-12-14 03:41:24 | INFO | train_inner | epoch 003:     69 / 305 loss=0.875, nll_loss=0.036, accuracy=77.5, wps=512.6, ups=0.67, wpb=769.1, bsz=32, num_updates=675, lr=8.15789e-06, gnorm=31.8, loss_scale=8, train_wall=37, wall=1091\n",
      "2020-12-14 03:42:02 | INFO | train_inner | epoch 003:     94 / 305 loss=0.92, nll_loss=0.038, accuracy=75, wps=508.5, ups=0.66, wpb=774.9, bsz=32, num_updates=700, lr=8.07018e-06, gnorm=34.937, loss_scale=8, train_wall=38, wall=1129\n",
      "2020-12-14 03:42:41 | INFO | train_inner | epoch 003:    119 / 305 loss=0.944, nll_loss=0.038, accuracy=74.6, wps=516.3, ups=0.66, wpb=787.1, bsz=32, num_updates=725, lr=7.98246e-06, gnorm=30.352, loss_scale=8, train_wall=38, wall=1168\n",
      "2020-12-14 03:43:18 | INFO | train_inner | epoch 003:    144 / 305 loss=0.921, nll_loss=0.038, accuracy=74, wps=507, ups=0.66, wpb=769.5, bsz=32, num_updates=750, lr=7.89474e-06, gnorm=31.423, loss_scale=8, train_wall=38, wall=1206\n",
      "2020-12-14 03:43:56 | INFO | train_inner | epoch 003:    169 / 305 loss=0.885, nll_loss=0.037, accuracy=76.2, wps=506.3, ups=0.66, wpb=767.1, bsz=32, num_updates=775, lr=7.80702e-06, gnorm=32.281, loss_scale=8, train_wall=38, wall=1243\n",
      "2020-12-14 03:44:34 | INFO | train_inner | epoch 003:    194 / 305 loss=0.9, nll_loss=0.038, accuracy=75.2, wps=503.3, ups=0.66, wpb=764.4, bsz=32, num_updates=800, lr=7.7193e-06, gnorm=32.442, loss_scale=8, train_wall=38, wall=1281\n",
      "2020-12-14 03:45:12 | INFO | train_inner | epoch 003:    219 / 305 loss=0.919, nll_loss=0.038, accuracy=76.1, wps=509, ups=0.66, wpb=776.4, bsz=32, num_updates=825, lr=7.63158e-06, gnorm=44.229, loss_scale=8, train_wall=38, wall=1320\n",
      "2020-12-14 03:45:50 | INFO | train_inner | epoch 003:    244 / 305 loss=0.989, nll_loss=0.041, accuracy=73.4, wps=510.3, ups=0.66, wpb=775.6, bsz=32, num_updates=850, lr=7.54386e-06, gnorm=36.303, loss_scale=8, train_wall=38, wall=1358\n",
      "2020-12-14 03:46:28 | INFO | train_inner | epoch 003:    269 / 305 loss=0.935, nll_loss=0.039, accuracy=74, wps=507.2, ups=0.66, wpb=772, bsz=32, num_updates=875, lr=7.45614e-06, gnorm=51.004, loss_scale=8, train_wall=38, wall=1396\n",
      "2020-12-14 03:47:06 | INFO | train_inner | epoch 003:    294 / 305 loss=1.169, nll_loss=0.049, accuracy=68.6, wps=507.4, ups=0.66, wpb=764.2, bsz=32, num_updates=900, lr=7.36842e-06, gnorm=45.966, loss_scale=8, train_wall=38, wall=1433\n",
      "2020-12-14 03:47:22 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "2020-12-14 03:47:40 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 1.107 | nll_loss 0.046 | accuracy 71.7 | wps 1691.1 | wpb 191 | bsz 8 | num_updates 911 | best_accuracy 75.9\n",
      "2020-12-14 03:47:40 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2020-12-14 03:47:40 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)\n",
      "2020-12-14 03:47:40 | INFO | train | epoch 003 | loss 0.958 | nll_loss 0.04 | accuracy 74.1 | wps 489.7 | ups 0.64 | wpb 770.6 | bsz 31.9 | num_updates 911 | lr 7.32982e-06 | gnorm 37.231 | loss_scale 8 | train_wall 462 | wall 1467\n",
      "2020-12-14 03:47:40 | INFO | fairseq.trainer | begin training epoch 4\n",
      "2020-12-14 03:48:01 | INFO | train_inner | epoch 004:     14 / 305 loss=1.165, nll_loss=0.049, accuracy=68.1, wps=341, ups=0.46, wpb=746.3, bsz=31.4, num_updates=925, lr=7.2807e-06, gnorm=57.41, loss_scale=8, train_wall=37, wall=1488\n",
      "2020-12-14 03:48:39 | INFO | train_inner | epoch 004:     39 / 305 loss=0.641, nll_loss=0.027, accuracy=81.8, wps=505.1, ups=0.66, wpb=761.3, bsz=32, num_updates=950, lr=7.19298e-06, gnorm=38.421, loss_scale=8, train_wall=38, wall=1526\n",
      "2020-12-14 03:49:17 | INFO | train_inner | epoch 004:     64 / 305 loss=0.726, nll_loss=0.03, accuracy=80.2, wps=503.4, ups=0.65, wpb=769.6, bsz=32, num_updates=975, lr=7.10526e-06, gnorm=39.681, loss_scale=8, train_wall=38, wall=1564\n",
      "2020-12-14 03:49:55 | INFO | train_inner | epoch 004:     89 / 305 loss=0.652, nll_loss=0.026, accuracy=82, wps=517.3, ups=0.66, wpb=788.6, bsz=32, num_updates=1000, lr=7.01754e-06, gnorm=32.683, loss_scale=8, train_wall=38, wall=1602\n",
      "2020-12-14 03:50:33 | INFO | train_inner | epoch 004:    114 / 305 loss=0.731, nll_loss=0.031, accuracy=79.5, wps=499.7, ups=0.65, wpb=765.6, bsz=32, num_updates=1025, lr=6.92982e-06, gnorm=38.93, loss_scale=8, train_wall=38, wall=1640\n",
      "2020-12-14 03:51:11 | INFO | train_inner | epoch 004:    139 / 305 loss=0.662, nll_loss=0.028, accuracy=82.5, wps=505.8, ups=0.66, wpb=768.6, bsz=32, num_updates=1050, lr=6.84211e-06, gnorm=32.369, loss_scale=8, train_wall=38, wall=1678\n",
      "2020-12-14 03:51:49 | INFO | train_inner | epoch 004:    164 / 305 loss=0.619, nll_loss=0.026, accuracy=83.2, wps=506.7, ups=0.67, wpb=761.9, bsz=32, num_updates=1075, lr=6.75439e-06, gnorm=33.782, loss_scale=8, train_wall=38, wall=1716\n",
      "2020-12-14 03:52:27 | INFO | train_inner | epoch 004:    189 / 305 loss=0.689, nll_loss=0.028, accuracy=82.8, wps=514.5, ups=0.66, wpb=782.8, bsz=32, num_updates=1100, lr=6.66667e-06, gnorm=31.105, loss_scale=8, train_wall=38, wall=1754\n",
      "2020-12-14 03:53:05 | INFO | train_inner | epoch 004:    214 / 305 loss=0.681, nll_loss=0.029, accuracy=81.8, wps=500.1, ups=0.66, wpb=756.3, bsz=32, num_updates=1125, lr=6.57895e-06, gnorm=35.171, loss_scale=8, train_wall=38, wall=1792\n",
      "2020-12-14 03:53:43 | INFO | train_inner | epoch 004:    239 / 305 loss=0.699, nll_loss=0.029, accuracy=80.2, wps=509.8, ups=0.65, wpb=783.7, bsz=32, num_updates=1150, lr=6.49123e-06, gnorm=33.545, loss_scale=8, train_wall=38, wall=1830\n",
      "2020-12-14 03:54:21 | INFO | train_inner | epoch 004:    264 / 305 loss=0.723, nll_loss=0.03, accuracy=80.6, wps=512.8, ups=0.66, wpb=782.1, bsz=32, num_updates=1175, lr=6.40351e-06, gnorm=35.228, loss_scale=8, train_wall=38, wall=1868\n",
      "2020-12-14 03:54:59 | INFO | train_inner | epoch 004:    289 / 305 loss=0.633, nll_loss=0.026, accuracy=82.4, wps=511, ups=0.65, wpb=780.9, bsz=32, num_updates=1200, lr=6.31579e-06, gnorm=30.822, loss_scale=8, train_wall=38, wall=1906\n",
      "2020-12-14 03:55:23 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "2020-12-14 03:55:41 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 0.894 | nll_loss 0.037 | accuracy 77.3 | wps 1681 | wpb 191 | bsz 8 | num_updates 1216 | best_accuracy 77.3\n",
      "2020-12-14 03:55:41 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2020-12-14 03:55:50 | INFO | fairseq.checkpoint_utils | saved checkpoint ./checkpoints/checkpoint_best.pt (epoch 4 @ 1216 updates, score 77.3) (writing took 9.010156170999835 seconds)\n",
      "2020-12-14 03:55:50 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)\n",
      "2020-12-14 03:55:50 | INFO | train | epoch 004 | loss 0.697 | nll_loss 0.029 | accuracy 81 | wps 479.5 | ups 0.62 | wpb 770.6 | bsz 31.9 | num_updates 1216 | lr 6.25965e-06 | gnorm 35.663 | loss_scale 8 | train_wall 463 | wall 1957\n",
      "2020-12-14 03:55:50 | INFO | fairseq.trainer | begin training epoch 5\n",
      "2020-12-14 03:56:03 | INFO | train_inner | epoch 005:      9 / 305 loss=0.645, nll_loss=0.027, accuracy=82.8, wps=290.2, ups=0.39, wpb=743.2, bsz=31.2, num_updates=1225, lr=6.22807e-06, gnorm=31.716, loss_scale=8, train_wall=37, wall=1970\n",
      "2020-12-14 03:56:41 | INFO | train_inner | epoch 005:     34 / 305 loss=0.436, nll_loss=0.018, accuracy=89.4, wps=508.1, ups=0.66, wpb=774, bsz=32, num_updates=1250, lr=6.14035e-06, gnorm=31.136, loss_scale=8, train_wall=38, wall=2009\n",
      "2020-12-14 03:57:20 | INFO | train_inner | epoch 005:     59 / 305 loss=0.529, nll_loss=0.022, accuracy=86.4, wps=507.3, ups=0.65, wpb=781.4, bsz=32, num_updates=1275, lr=6.05263e-06, gnorm=39.567, loss_scale=8, train_wall=38, wall=2047\n",
      "2020-12-14 03:57:58 | INFO | train_inner | epoch 005:     84 / 305 loss=0.53, nll_loss=0.022, accuracy=86.4, wps=515.1, ups=0.66, wpb=786.2, bsz=32, num_updates=1300, lr=5.96491e-06, gnorm=34.641, loss_scale=8, train_wall=38, wall=2085\n",
      "2020-12-14 03:58:36 | INFO | train_inner | epoch 005:    109 / 305 loss=0.523, nll_loss=0.022, accuracy=87, wps=510.8, ups=0.66, wpb=775.3, bsz=32, num_updates=1325, lr=5.87719e-06, gnorm=33.318, loss_scale=8, train_wall=38, wall=2123\n",
      "2020-12-14 03:59:14 | INFO | train_inner | epoch 005:    134 / 305 loss=0.488, nll_loss=0.02, accuracy=86.4, wps=507.8, ups=0.66, wpb=773.9, bsz=32, num_updates=1350, lr=5.78947e-06, gnorm=33.969, loss_scale=8, train_wall=38, wall=2161\n",
      "2020-12-14 03:59:52 | INFO | train_inner | epoch 005:    159 / 305 loss=0.56, nll_loss=0.023, accuracy=85.5, wps=513.1, ups=0.67, wpb=769.8, bsz=32, num_updates=1375, lr=5.70175e-06, gnorm=32.826, loss_scale=8, train_wall=37, wall=2199\n",
      "2020-12-14 04:00:30 | INFO | train_inner | epoch 005:    184 / 305 loss=0.42, nll_loss=0.017, accuracy=89.9, wps=507.2, ups=0.66, wpb=770.3, bsz=32, num_updates=1400, lr=5.61404e-06, gnorm=28.245, loss_scale=8, train_wall=38, wall=2237\n",
      "2020-12-14 04:01:08 | INFO | train_inner | epoch 005:    209 / 305 loss=0.503, nll_loss=0.021, accuracy=86.8, wps=507.5, ups=0.66, wpb=769.9, bsz=31.9, num_updates=1425, lr=5.52632e-06, gnorm=39.106, loss_scale=8, train_wall=38, wall=2275\n",
      "2020-12-14 04:01:45 | INFO | train_inner | epoch 005:    234 / 305 loss=0.53, nll_loss=0.022, accuracy=87.1, wps=507.5, ups=0.66, wpb=767.5, bsz=32, num_updates=1450, lr=5.4386e-06, gnorm=32.717, loss_scale=8, train_wall=38, wall=2312\n",
      "2020-12-14 04:02:23 | INFO | train_inner | epoch 005:    259 / 305 loss=0.49, nll_loss=0.02, accuracy=86.9, wps=509.1, ups=0.66, wpb=774.4, bsz=32, num_updates=1475, lr=5.35088e-06, gnorm=29.265, loss_scale=8, train_wall=38, wall=2351\n",
      "2020-12-14 04:03:01 | INFO | train_inner | epoch 005:    284 / 305 loss=0.505, nll_loss=0.021, accuracy=86, wps=504.2, ups=0.67, wpb=755.9, bsz=32, num_updates=1500, lr=5.26316e-06, gnorm=35.289, loss_scale=8, train_wall=37, wall=2388\n",
      "2020-12-14 04:03:32 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "2020-12-14 04:03:50 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 0.939 | nll_loss 0.039 | accuracy 77.2 | wps 1686.5 | wpb 191 | bsz 8 | num_updates 1521 | best_accuracy 77.3\n",
      "2020-12-14 04:03:50 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2020-12-14 04:03:50 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)\n",
      "2020-12-14 04:03:50 | INFO | train | epoch 005 | loss 0.505 | nll_loss 0.021 | accuracy 86.9 | wps 489.7 | ups 0.64 | wpb 770.6 | bsz 31.9 | num_updates 1521 | lr 5.18947e-06 | gnorm 33.224 | loss_scale 8 | train_wall 461 | wall 2437\n",
      "2020-12-14 04:03:50 | INFO | fairseq.trainer | begin training epoch 6\n",
      "2020-12-14 04:03:56 | INFO | train_inner | epoch 006:      4 / 305 loss=0.52, nll_loss=0.022, accuracy=86.7, wps=343.3, ups=0.45, wpb=754.9, bsz=31.4, num_updates=1525, lr=5.17544e-06, gnorm=30.175, loss_scale=8, train_wall=37, wall=2443\n",
      "2020-12-14 04:04:34 | INFO | train_inner | epoch 006:     29 / 305 loss=0.398, nll_loss=0.016, accuracy=89.1, wps=507.6, ups=0.66, wpb=772.9, bsz=32, num_updates=1550, lr=5.08772e-06, gnorm=32.474, loss_scale=8, train_wall=38, wall=2481\n",
      "2020-12-14 04:05:12 | INFO | train_inner | epoch 006:     54 / 305 loss=0.411, nll_loss=0.017, accuracy=88.5, wps=509.8, ups=0.66, wpb=771.2, bsz=32, num_updates=1575, lr=5e-06, gnorm=31.661, loss_scale=8, train_wall=38, wall=2519\n",
      "2020-12-14 04:05:50 | INFO | train_inner | epoch 006:     79 / 305 loss=0.387, nll_loss=0.016, accuracy=89.1, wps=510.2, ups=0.66, wpb=775.7, bsz=32, num_updates=1600, lr=4.91228e-06, gnorm=29.095, loss_scale=8, train_wall=38, wall=2557\n",
      "2020-12-14 04:06:27 | INFO | train_inner | epoch 006:    104 / 305 loss=0.416, nll_loss=0.017, accuracy=88, wps=505.4, ups=0.66, wpb=761.4, bsz=32, num_updates=1625, lr=4.82456e-06, gnorm=38.798, loss_scale=8, train_wall=38, wall=2595\n",
      "2020-12-14 04:07:06 | INFO | train_inner | epoch 006:    129 / 305 loss=0.386, nll_loss=0.016, accuracy=90.9, wps=506.4, ups=0.66, wpb=771.8, bsz=32, num_updates=1650, lr=4.73684e-06, gnorm=30.434, loss_scale=8, train_wall=38, wall=2633\n",
      "2020-12-14 04:07:44 | INFO | train_inner | epoch 006:    154 / 305 loss=0.398, nll_loss=0.017, accuracy=90, wps=502.5, ups=0.66, wpb=766.9, bsz=31.9, num_updates=1675, lr=4.64912e-06, gnorm=30.443, loss_scale=8, train_wall=38, wall=2671\n",
      "2020-12-14 04:08:22 | INFO | train_inner | epoch 006:    179 / 305 loss=0.365, nll_loss=0.015, accuracy=91, wps=512.3, ups=0.66, wpb=781.1, bsz=32, num_updates=1700, lr=4.5614e-06, gnorm=32.601, loss_scale=8, train_wall=38, wall=2709\n",
      "2020-12-14 04:09:00 | INFO | train_inner | epoch 006:    204 / 305 loss=0.407, nll_loss=0.017, accuracy=90, wps=504.8, ups=0.66, wpb=764, bsz=32, num_updates=1725, lr=4.47368e-06, gnorm=33.955, loss_scale=8, train_wall=38, wall=2747\n",
      "2020-12-14 04:09:38 | INFO | train_inner | epoch 006:    229 / 305 loss=0.379, nll_loss=0.016, accuracy=89, wps=507.1, ups=0.66, wpb=770.3, bsz=32, num_updates=1750, lr=4.38596e-06, gnorm=35.433, loss_scale=8, train_wall=38, wall=2785\n",
      "2020-12-14 04:10:16 | INFO | train_inner | epoch 006:    254 / 305 loss=0.399, nll_loss=0.016, accuracy=89, wps=512.9, ups=0.65, wpb=783.6, bsz=32, num_updates=1775, lr=4.29825e-06, gnorm=41.476, loss_scale=8, train_wall=38, wall=2823\n",
      "2020-12-14 04:10:54 | INFO | train_inner | epoch 006:    279 / 305 loss=0.386, nll_loss=0.016, accuracy=89.8, wps=513.8, ups=0.66, wpb=774.8, bsz=32, num_updates=1800, lr=4.21053e-06, gnorm=31.535, loss_scale=8, train_wall=38, wall=2861\n",
      "2020-12-14 04:11:31 | INFO | train_inner | epoch 006:    304 / 305 loss=0.369, nll_loss=0.015, accuracy=89.6, wps=509.7, ups=0.66, wpb=770.7, bsz=32, num_updates=1825, lr=4.12281e-06, gnorm=41.941, loss_scale=8, train_wall=38, wall=2898\n",
      "2020-12-14 04:11:32 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "2020-12-14 04:11:50 | INFO | valid | epoch 006 | valid on 'valid' subset | loss 1.094 | nll_loss 0.046 | accuracy 76.7 | wps 1691.1 | wpb 191 | bsz 8 | num_updates 1826 | best_accuracy 77.3\n",
      "2020-12-14 04:11:50 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2020-12-14 04:11:50 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)\n",
      "2020-12-14 04:11:50 | INFO | train | epoch 006 | loss 0.392 | nll_loss 0.016 | accuracy 89.5 | wps 489.8 | ups 0.64 | wpb 770.6 | bsz 31.9 | num_updates 1826 | lr 4.1193e-06 | gnorm 34.112 | loss_scale 8 | train_wall 461 | wall 2917\n",
      "2020-12-14 04:11:50 | INFO | fairseq.trainer | begin training epoch 7\n",
      "2020-12-14 04:12:26 | INFO | train_inner | epoch 007:     24 / 305 loss=0.29, nll_loss=0.012, accuracy=91.8, wps=348.6, ups=0.45, wpb=768.2, bsz=31.4, num_updates=1850, lr=4.03509e-06, gnorm=40.896, loss_scale=8, train_wall=38, wall=2953\n",
      "2020-12-14 04:13:04 | INFO | train_inner | epoch 007:     49 / 305 loss=0.277, nll_loss=0.012, accuracy=93.1, wps=511.7, ups=0.66, wpb=769.9, bsz=32, num_updates=1875, lr=3.94737e-06, gnorm=35.853, loss_scale=8, train_wall=38, wall=2991\n",
      "2020-12-14 04:13:42 | INFO | train_inner | epoch 007:     74 / 305 loss=0.306, nll_loss=0.013, accuracy=91.9, wps=509.3, ups=0.65, wpb=778.1, bsz=32, num_updates=1900, lr=3.85965e-06, gnorm=65.256, loss_scale=8, train_wall=38, wall=3029\n",
      "2020-12-14 04:14:20 | INFO | train_inner | epoch 007:     99 / 305 loss=0.329, nll_loss=0.014, accuracy=92.2, wps=510.1, ups=0.67, wpb=765.5, bsz=32, num_updates=1925, lr=3.77193e-06, gnorm=62.549, loss_scale=8, train_wall=37, wall=3067\n",
      "2020-12-14 04:14:57 | INFO | train_inner | epoch 007:    124 / 305 loss=0.295, nll_loss=0.012, accuracy=91.8, wps=517.4, ups=0.67, wpb=776.2, bsz=32, num_updates=1950, lr=3.68421e-06, gnorm=40.805, loss_scale=8, train_wall=37, wall=3104\n",
      "2020-12-14 04:15:35 | INFO | train_inner | epoch 007:    149 / 305 loss=0.303, nll_loss=0.013, accuracy=92, wps=508.6, ups=0.66, wpb=774.5, bsz=32, num_updates=1975, lr=3.59649e-06, gnorm=35.575, loss_scale=8, train_wall=38, wall=3142\n",
      "2020-12-14 04:16:13 | INFO | train_inner | epoch 007:    174 / 305 loss=0.301, nll_loss=0.013, accuracy=91.1, wps=508.8, ups=0.66, wpb=767.5, bsz=32, num_updates=2000, lr=3.50877e-06, gnorm=34.844, loss_scale=8, train_wall=38, wall=3180\n",
      "2020-12-14 04:16:51 | INFO | train_inner | epoch 007:    199 / 305 loss=0.341, nll_loss=0.014, accuracy=90.5, wps=505.3, ups=0.66, wpb=764, bsz=32, num_updates=2025, lr=3.42105e-06, gnorm=34.924, loss_scale=8, train_wall=38, wall=3218\n",
      "2020-12-14 04:17:28 | INFO | train_inner | epoch 007:    224 / 305 loss=0.275, nll_loss=0.011, accuracy=93.1, wps=513.3, ups=0.67, wpb=771.5, bsz=32, num_updates=2050, lr=3.33333e-06, gnorm=29.046, loss_scale=8, train_wall=37, wall=3255\n",
      "2020-12-14 04:18:06 | INFO | train_inner | epoch 007:    249 / 305 loss=0.32, nll_loss=0.014, accuracy=91.3, wps=501.6, ups=0.67, wpb=753.9, bsz=31.9, num_updates=2075, lr=3.24561e-06, gnorm=38.949, loss_scale=8, train_wall=37, wall=3293\n",
      "2020-12-14 04:18:44 | INFO | train_inner | epoch 007:    274 / 305 loss=0.335, nll_loss=0.014, accuracy=90.8, wps=513.2, ups=0.66, wpb=783, bsz=32, num_updates=2100, lr=3.15789e-06, gnorm=41.208, loss_scale=8, train_wall=38, wall=3331\n",
      "2020-12-14 04:19:22 | INFO | train_inner | epoch 007:    299 / 305 loss=0.308, nll_loss=0.013, accuracy=92.4, wps=512.2, ups=0.66, wpb=774.4, bsz=32, num_updates=2125, lr=3.07018e-06, gnorm=32.999, loss_scale=8, train_wall=38, wall=3369\n",
      "2020-12-14 04:19:30 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "2020-12-14 04:19:48 | INFO | valid | epoch 007 | valid on 'valid' subset | loss 1.118 | nll_loss 0.047 | accuracy 77.2 | wps 1697.6 | wpb 191 | bsz 8 | num_updates 2131 | best_accuracy 77.3\n",
      "2020-12-14 04:19:48 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2020-12-14 04:19:48 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)\n",
      "2020-12-14 04:19:48 | INFO | train | epoch 007 | loss 0.305 | nll_loss 0.013 | accuracy 91.9 | wps 491.7 | ups 0.64 | wpb 770.6 | bsz 31.9 | num_updates 2131 | lr 3.04912e-06 | gnorm 40.748 | loss_scale 8 | train_wall 460 | wall 3395\n",
      "2020-12-14 04:19:48 | INFO | fairseq.trainer | begin training epoch 8\n",
      "2020-12-14 04:20:16 | INFO | train_inner | epoch 008:     19 / 305 loss=0.23, nll_loss=0.01, accuracy=94.8, wps=347.3, ups=0.46, wpb=757.6, bsz=31.4, num_updates=2150, lr=2.98246e-06, gnorm=25.388, loss_scale=8, train_wall=37, wall=3424\n",
      "2020-12-14 04:20:54 | INFO | train_inner | epoch 008:     44 / 305 loss=0.234, nll_loss=0.01, accuracy=95, wps=503.4, ups=0.66, wpb=760.2, bsz=32, num_updates=2175, lr=2.89474e-06, gnorm=39.27, loss_scale=8, train_wall=38, wall=3461\n",
      "2020-12-14 04:21:32 | INFO | train_inner | epoch 008:     69 / 305 loss=0.27, nll_loss=0.011, accuracy=92.9, wps=504.5, ups=0.66, wpb=766.2, bsz=32, num_updates=2200, lr=2.80702e-06, gnorm=34.187, loss_scale=8, train_wall=38, wall=3499\n",
      "2020-12-14 04:22:10 | INFO | train_inner | epoch 008:     94 / 305 loss=0.221, nll_loss=0.009, accuracy=94.6, wps=514.7, ups=0.66, wpb=783.9, bsz=32, num_updates=2225, lr=2.7193e-06, gnorm=36.806, loss_scale=8, train_wall=38, wall=3537\n",
      "2020-12-14 04:22:48 | INFO | train_inner | epoch 008:    119 / 305 loss=0.266, nll_loss=0.011, accuracy=93.9, wps=514, ups=0.66, wpb=774.1, bsz=32, num_updates=2250, lr=2.63158e-06, gnorm=31.791, loss_scale=8, train_wall=38, wall=3575\n",
      "2020-12-14 04:23:26 | INFO | train_inner | epoch 008:    144 / 305 loss=0.244, nll_loss=0.01, accuracy=93.8, wps=509.3, ups=0.66, wpb=767.9, bsz=32, num_updates=2275, lr=2.54386e-06, gnorm=34.124, loss_scale=8, train_wall=38, wall=3613\n",
      "2020-12-14 04:24:03 | INFO | train_inner | epoch 008:    169 / 305 loss=0.2, nll_loss=0.008, accuracy=95.2, wps=512.2, ups=0.66, wpb=773.2, bsz=32, num_updates=2300, lr=2.45614e-06, gnorm=27.901, loss_scale=8, train_wall=38, wall=3650\n",
      "2020-12-14 04:24:42 | INFO | train_inner | epoch 008:    194 / 305 loss=0.221, nll_loss=0.009, accuracy=95, wps=512.3, ups=0.65, wpb=782.8, bsz=32, num_updates=2325, lr=2.36842e-06, gnorm=28.479, loss_scale=8, train_wall=38, wall=3689\n",
      "2020-12-14 04:25:19 | INFO | train_inner | epoch 008:    219 / 305 loss=0.229, nll_loss=0.01, accuracy=94.5, wps=499.2, ups=0.66, wpb=757.2, bsz=31.9, num_updates=2350, lr=2.2807e-06, gnorm=29.126, loss_scale=8, train_wall=38, wall=3727\n",
      "2020-12-14 04:25:57 | INFO | train_inner | epoch 008:    244 / 305 loss=0.299, nll_loss=0.013, accuracy=92.9, wps=509.6, ups=0.67, wpb=763.2, bsz=32, num_updates=2375, lr=2.19298e-06, gnorm=33.035, loss_scale=8, train_wall=37, wall=3764\n",
      "2020-12-14 04:26:35 | INFO | train_inner | epoch 008:    269 / 305 loss=0.233, nll_loss=0.01, accuracy=93.8, wps=510.7, ups=0.65, wpb=784, bsz=32, num_updates=2400, lr=2.10526e-06, gnorm=37.569, loss_scale=8, train_wall=38, wall=3802\n",
      "2020-12-14 04:27:13 | INFO | train_inner | epoch 008:    294 / 305 loss=0.308, nll_loss=0.013, accuracy=91.8, wps=516.1, ups=0.67, wpb=773.2, bsz=32, num_updates=2425, lr=2.01754e-06, gnorm=37.597, loss_scale=8, train_wall=37, wall=3840\n",
      "2020-12-14 04:27:29 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "2020-12-14 04:27:46 | INFO | valid | epoch 008 | valid on 'valid' subset | loss 1.211 | nll_loss 0.051 | accuracy 76.5 | wps 1693.2 | wpb 191 | bsz 8 | num_updates 2436 | best_accuracy 77.3\n",
      "2020-12-14 04:27:46 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2020-12-14 04:27:46 | INFO | fairseq_cli.train | end of epoch 8 (average epoch stats below)\n",
      "2020-12-14 04:27:46 | INFO | train | epoch 008 | loss 0.248 | nll_loss 0.01 | accuracy 93.9 | wps 491.2 | ups 0.64 | wpb 770.6 | bsz 31.9 | num_updates 2436 | lr 1.97895e-06 | gnorm 33.244 | loss_scale 8 | train_wall 460 | wall 3873\n",
      "2020-12-14 04:27:46 | INFO | fairseq.trainer | begin training epoch 9\n",
      "2020-12-14 04:28:07 | INFO | train_inner | epoch 009:     14 / 305 loss=0.214, nll_loss=0.009, accuracy=94.5, wps=345.1, ups=0.46, wpb=753.4, bsz=31.4, num_updates=2450, lr=1.92982e-06, gnorm=32.338, loss_scale=8, train_wall=37, wall=3894\n",
      "2020-12-14 04:28:45 | INFO | train_inner | epoch 009:     39 / 305 loss=0.169, nll_loss=0.007, accuracy=96, wps=511.2, ups=0.66, wpb=778.6, bsz=32, num_updates=2475, lr=1.84211e-06, gnorm=28.136, loss_scale=8, train_wall=38, wall=3932\n",
      "2020-12-14 04:29:23 | INFO | train_inner | epoch 009:     64 / 305 loss=0.204, nll_loss=0.009, accuracy=94.4, wps=508.7, ups=0.66, wpb=766.8, bsz=32, num_updates=2500, lr=1.75439e-06, gnorm=32.842, loss_scale=8, train_wall=38, wall=3970\n",
      "2020-12-14 04:30:01 | INFO | train_inner | epoch 009:     89 / 305 loss=0.178, nll_loss=0.007, accuracy=95.5, wps=513.8, ups=0.66, wpb=773.2, bsz=32, num_updates=2525, lr=1.66667e-06, gnorm=31.29, loss_scale=8, train_wall=38, wall=4008\n",
      "2020-12-14 04:30:39 | INFO | train_inner | epoch 009:    114 / 305 loss=0.185, nll_loss=0.008, accuracy=95.1, wps=517.3, ups=0.66, wpb=785.9, bsz=31.9, num_updates=2550, lr=1.57895e-06, gnorm=34.075, loss_scale=8, train_wall=38, wall=4046\n",
      "2020-12-14 04:31:16 | INFO | train_inner | epoch 009:    139 / 305 loss=0.26, nll_loss=0.011, accuracy=94, wps=504.6, ups=0.66, wpb=761.8, bsz=32, num_updates=2575, lr=1.49123e-06, gnorm=33.45, loss_scale=8, train_wall=38, wall=4083\n",
      "2020-12-14 04:31:55 | INFO | train_inner | epoch 009:    164 / 305 loss=0.196, nll_loss=0.008, accuracy=95.1, wps=511.8, ups=0.65, wpb=786.2, bsz=32, num_updates=2600, lr=1.40351e-06, gnorm=25.327, loss_scale=8, train_wall=38, wall=4122\n",
      "2020-12-14 04:32:33 | INFO | train_inner | epoch 009:    189 / 305 loss=0.223, nll_loss=0.009, accuracy=94.6, wps=511.2, ups=0.66, wpb=773.2, bsz=32, num_updates=2625, lr=1.31579e-06, gnorm=29.439, loss_scale=8, train_wall=38, wall=4160\n",
      "2020-12-14 04:33:10 | INFO | train_inner | epoch 009:    214 / 305 loss=0.206, nll_loss=0.009, accuracy=94.6, wps=507.3, ups=0.66, wpb=765.2, bsz=32, num_updates=2650, lr=1.22807e-06, gnorm=27.139, loss_scale=8, train_wall=38, wall=4197\n",
      "2020-12-14 04:33:48 | INFO | train_inner | epoch 009:    239 / 305 loss=0.162, nll_loss=0.007, accuracy=95.9, wps=510.4, ups=0.66, wpb=772, bsz=32, num_updates=2675, lr=1.14035e-06, gnorm=37.754, loss_scale=8, train_wall=38, wall=4235\n",
      "2020-12-14 04:34:26 | INFO | train_inner | epoch 009:    264 / 305 loss=0.207, nll_loss=0.009, accuracy=95.8, wps=506.1, ups=0.66, wpb=768.2, bsz=32, num_updates=2700, lr=1.05263e-06, gnorm=28.933, loss_scale=8, train_wall=38, wall=4273\n",
      "2020-12-14 04:35:04 | INFO | train_inner | epoch 009:    289 / 305 loss=0.187, nll_loss=0.008, accuracy=95, wps=508.2, ups=0.66, wpb=767.5, bsz=32, num_updates=2725, lr=9.64912e-07, gnorm=30.824, loss_scale=8, train_wall=38, wall=4311\n",
      "2020-12-14 04:35:27 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "2020-12-14 04:35:45 | INFO | valid | epoch 009 | valid on 'valid' subset | loss 1.298 | nll_loss 0.054 | accuracy 76.4 | wps 1691.5 | wpb 191 | bsz 8 | num_updates 2741 | best_accuracy 77.3\n",
      "2020-12-14 04:35:45 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2020-12-14 04:35:45 | INFO | fairseq_cli.train | end of epoch 9 (average epoch stats below)\n",
      "2020-12-14 04:35:45 | INFO | train | epoch 009 | loss 0.196 | nll_loss 0.008 | accuracy 95.1 | wps 490.9 | ups 0.64 | wpb 770.6 | bsz 31.9 | num_updates 2741 | lr 9.08772e-07 | gnorm 30.553 | loss_scale 8 | train_wall 460 | wall 4352\n",
      "2020-12-14 04:35:45 | INFO | fairseq.trainer | begin training epoch 10\n",
      "2020-12-14 04:35:58 | INFO | train_inner | epoch 010:      9 / 305 loss=0.191, nll_loss=0.008, accuracy=94.9, wps=344.5, ups=0.46, wpb=751, bsz=31.4, num_updates=2750, lr=8.77193e-07, gnorm=28.576, loss_scale=8, train_wall=37, wall=4365\n",
      "2020-12-14 04:36:36 | INFO | train_inner | epoch 010:     34 / 305 loss=0.205, nll_loss=0.009, accuracy=94, wps=506.5, ups=0.66, wpb=766.3, bsz=32, num_updates=2775, lr=7.89474e-07, gnorm=31.926, loss_scale=8, train_wall=38, wall=4403\n",
      "2020-12-14 04:37:14 | INFO | train_inner | epoch 010:     59 / 305 loss=0.177, nll_loss=0.007, accuracy=95.9, wps=512.2, ups=0.66, wpb=780.8, bsz=32, num_updates=2800, lr=7.01754e-07, gnorm=29.035, loss_scale=8, train_wall=38, wall=4441\n",
      "2020-12-14 04:37:52 | INFO | train_inner | epoch 010:     84 / 305 loss=0.184, nll_loss=0.008, accuracy=95.8, wps=513.8, ups=0.66, wpb=777.9, bsz=32, num_updates=2825, lr=6.14035e-07, gnorm=31.221, loss_scale=8, train_wall=38, wall=4479\n",
      "2020-12-14 04:38:30 | INFO | train_inner | epoch 010:    109 / 305 loss=0.161, nll_loss=0.007, accuracy=96.5, wps=502.5, ups=0.66, wpb=760.4, bsz=32, num_updates=2850, lr=5.26316e-07, gnorm=25.892, loss_scale=8, train_wall=38, wall=4517\n",
      "2020-12-14 04:39:08 | INFO | train_inner | epoch 010:    134 / 305 loss=0.136, nll_loss=0.006, accuracy=96.5, wps=509.1, ups=0.66, wpb=776.2, bsz=31.9, num_updates=2875, lr=4.38596e-07, gnorm=24.767, loss_scale=8, train_wall=38, wall=4555\n",
      "2020-12-14 04:39:46 | INFO | train_inner | epoch 010:    159 / 305 loss=0.147, nll_loss=0.006, accuracy=96.5, wps=503.6, ups=0.66, wpb=765.6, bsz=32, num_updates=2900, lr=3.50877e-07, gnorm=24.976, loss_scale=8, train_wall=38, wall=4593\n",
      "2020-12-14 04:40:25 | INFO | train_inner | epoch 010:    184 / 305 loss=0.178, nll_loss=0.007, accuracy=95.4, wps=502, ups=0.65, wpb=772.8, bsz=32, num_updates=2925, lr=2.63158e-07, gnorm=28.783, loss_scale=8, train_wall=38, wall=4632\n",
      "2020-12-14 04:41:03 | INFO | train_inner | epoch 010:    209 / 305 loss=0.144, nll_loss=0.006, accuracy=96, wps=497.7, ups=0.65, wpb=766.3, bsz=32, num_updates=2950, lr=1.75439e-07, gnorm=23.465, loss_scale=8, train_wall=38, wall=4670\n",
      "2020-12-14 04:41:41 | INFO | train_inner | epoch 010:    234 / 305 loss=0.207, nll_loss=0.009, accuracy=94.9, wps=496.5, ups=0.65, wpb=759.7, bsz=32, num_updates=2975, lr=8.77193e-08, gnorm=33.331, loss_scale=8, train_wall=38, wall=4708\n",
      "2020-12-14 04:42:20 | INFO | train_inner | epoch 010:    259 / 305 loss=0.207, nll_loss=0.009, accuracy=94.4, wps=503.5, ups=0.65, wpb=772.5, bsz=32, num_updates=3000, lr=0, gnorm=40.379, loss_scale=8, train_wall=38, wall=4747\n",
      "2020-12-14 04:42:20 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "2020-12-14 04:42:37 | INFO | valid | epoch 010 | valid on 'valid' subset | loss 1.326 | nll_loss 0.055 | accuracy 77.1 | wps 1669.6 | wpb 191 | bsz 8 | num_updates 3000 | best_accuracy 77.3\n",
      "2020-12-14 04:42:37 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2020-12-14 04:42:37 | INFO | fairseq_cli.train | end of epoch 10 (average epoch stats below)\n",
      "2020-12-14 04:42:37 | INFO | train | epoch 010 | loss 0.175 | nll_loss 0.007 | accuracy 95.5 | wps 483.2 | ups 0.63 | wpb 769.6 | bsz 32 | num_updates 3000 | lr 0 | gnorm 29.362 | loss_scale 8 | train_wall 394 | wall 4764\n",
      "2020-12-14 04:42:37 | INFO | fairseq_cli.train | done training in 4756.7 seconds\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D2uv-ospUP_A"
   },
   "source": [
    "## Post training\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oWxBkO4fK4SU"
   },
   "source": [
    "Save the trained model to GoogleDrive."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "yNA2jki1vATj",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "8506f185-4654-4209-d00c-84267a765aae"
   },
   "source": [
    "%cd /content/\n",
    "%cp -r CommonsenseQA/ drive/My\\ Drive/EECS595_final_project/CSQA_Roberta"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "/content\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JbYEHMOnLeAd"
   },
   "source": [
    "Check model performance on validation set."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "JD7MGYhBKUcR",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "12848f76-9237-4c5e-ce5f-1b4c24119701"
   },
   "source": [
    "%cd /content/CommonsenseQA/fairseq/examples/roberta/commonsense_qa\n",
    "\n",
    "import json\n",
    "import torch\n",
    "from fairseq.models.roberta import RobertaModel\n",
    "import commonsense_qa_task  # load the Commonsense QA task\n",
    "\n",
    "base_dir = '/content/CommonsenseQA'\n",
    "roberta = RobertaModel.from_pretrained(base_dir + '/fairseq/checkpoints', 'checkpoint_best.pt', base_dir + '/data/CommonsenseQA')\n",
    "roberta.eval()  # disable dropout\n",
    "\n",
    "roberta.cuda()  # use the GPU (optional)\n",
    "nsamples, ncorrect = 0, 0\n",
    "wrong = []\n",
    "with open(base_dir + '/data/CommonsenseQA/valid.jsonl') as h:\n",
    "    print(3)\n",
    "    for line in h:\n",
    "        example = json.loads(line)\n",
    "        scores = []\n",
    "        for choice in example['question']['choices']:\n",
    "            input = roberta.encode(\n",
    "                'Q: ' + example['question']['stem'],\n",
    "                'A: ' + choice['text'],\n",
    "                no_separator=True\n",
    "            )\n",
    "            score = roberta.predict('sentence_classification_head', input, return_logits=True)\n",
    "            scores.append(score)\n",
    "\n",
    "        pred = torch.cat(scores).argmax()\n",
    "        answer = ord(example['answerKey']) - ord('A')\n",
    "        nsamples += 1\n",
    "        if pred == answer:\n",
    "            ncorrect += 1\n",
    "        else:\n",
    "            example['predicted'] = chr(ord('A') + pred)\n",
    "            example['scores'] = {chr(ord('A') + i): s.data.item() for (i, s) in enumerate(scores)}\n",
    "            wrong.append(json.dumps(example))\n",
    "\n",
    "\n",
    "print(f'Accuracy: {ncorrect}/{nsamples} = {ncorrect / float(nsamples)}')"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "2020-12-14 04:45:33 | INFO | fairseq.file_utils | loading archive file /content/CommonsenseQA/fairseq/checkpoints\n",
      "2020-12-14 04:45:33 | INFO | fairseq.file_utils | loading archive file /content/CommonsenseQA/data/CommonsenseQA\n"
     ],
     "name": "stderr"
    },
    {
     "output_type": "stream",
     "text": [
      "/content/CommonsenseQA/fairseq/examples/roberta/commonsense_qa\n",
      "| dictionary: 50265 types\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "stream",
     "text": [
      "2020-12-14 04:45:47 | INFO | fairseq.models.roberta.model | Namespace(activation_dropout=0.0, activation_fn='gelu', adam_betas='(0.9, 0.98)', adam_eps=1e-06, all_gather_list_size=16384, arch='roberta_large', attention_dropout=0.1, batch_size=8, batch_size_valid=8, best_checkpoint_metric='accuracy', bf16=False, bpe='gpt2', broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=0.0, cpu=False, criterion='sentence_ranking', curriculum=0, data='/content/CommonsenseQA/data/CommonsenseQA', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=1, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', dropout=0.1, empty_cache_freq=0, encoder_attention_heads=16, encoder_embed_dim=1024, encoder_ffn_embed_dim=4096, encoder_layerdrop=0, encoder_layers=24, encoder_layers_to_keep=None, end_learning_rate=0.0, fast_stat_sync=False, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, force_anneal=None, fp16=True, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='test', gpt2_encoder_json='https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', gpt2_vocab_bpe='https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe', init_token=0, keep_best_checkpoints=-1, keep_interval_updates=-1, keep_last_epochs=-1, load_checkpoint_heads=True, localsgd_frequency=3, log_format='simple', log_interval=25, lr=[1e-05], lr_scheduler='polynomial_decay', max_epoch=0, max_positions=512, max_source_positions=512, max_target_positions=512, max_tokens=None, max_tokens_valid=None, max_update=3000, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, min_lr=-1.0, model_parallel_size=1, no_epoch_checkpoints=True, no_last_checkpoints=True, no_progress_bar=False, no_save=False, no_save_optimizer_state=True, no_seed_provided=False, nprocs_per_node=1, num_classes=5, num_shards=1, num_workers=1, optimizer='adam', optimizer_overrides='{}', patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, pooler_activation_fn='tanh', pooler_dropout=0.0, power=1.0, profile=False, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, ranking_head_name='sentence_classification_head', required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, restore_file='/content/roberta.large/model.pt', save_dir='./checkpoints', save_interval=1, save_interval_updates=0, save_predictions=None, scoring='bleu', seed=23, sentence_avg=False, shard_id=0, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, spectral_norm_classification_head=False, stop_time_hours=0, task='commonsense_qa', tensorboard_logdir=None, threshold_loss_scale=None, tokenizer=None, total_num_update=3000, tpu=False, train_subset='train', untie_weights_roberta=False, update_freq=[4], use_bmuf=False, use_old_adam=False, user_dir='/content/CommonsenseQA/fairseq/examples/roberta/commonsense_qa', valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, warmup_updates=150, weight_decay=0.01, zero_sharding='none')\n"
     ],
     "name": "stderr"
    },
    {
     "output_type": "stream",
     "text": [
      "3\n",
      "Accuracy: 945/1221 = 0.773955773955774\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pgK2GOdaVu5l"
   },
   "source": [
    "## Result Report\n",
    "*   Training Accuracy: 94.4% \n",
    "*   Validation Accuracy: 77.4% \n",
    "\n",
    "\n"
   ]
  }
 ]
}