{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "ConvEnt_mnli.ipynb",
   "provenance": [],
   "collapsed_sections": [],
   "toc_visible": true
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "accelerator": "GPU",
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9eIUz6Xrk7Mn"
   },
   "source": [
    "# ConvEnt: Tuned with Knowledge\n",
    "\n",
    "EECS 595 Final Project, Task 2: Conversation Entailment\n",
    "\n",
    "* Team ID: 2\n",
    "* Credit: Ziqiao Ma, Qingyi Chen, Xueming Xu\n",
    "* Last update: 2020.12.16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g7BQNAknKvsn"
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PrMYC3StmXpm"
   },
   "source": [
    "## Colab setups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2LeDbHL6oLFI"
   },
   "source": [
    "Run this cell load the autoreload extension."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "xUiA5dX3yFGX"
   },
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "np_T5dXFoSrk"
   },
   "source": [
    "Run the following cell to mount your Google Drive."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "s36tQoeYVLA0",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "e4c7db75-3b01-4bff-da3d-209485c0e636"
   },
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mLAALYTAo25M"
   },
   "source": [
    "Test if script files are located."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "9KVidViv0AO2"
   },
   "source": [
    "import os\n",
    "import sys"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aB4aTTM14sCE"
   },
   "source": [
    "Check if dataset file is located, you should see `eat_test_unlabeled.json` and `eat_train.json` in the folder."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-lrrOs4d4lkE",
    "outputId": "5f5b3b7f-e723-43af-8628-5f8b21503cb7"
   },
   "source": [
    "!ls /content/drive/Shareddrives/EECS595-Fall2020/Final_Project_Common/Conversational_Entailment/"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "act_tag.json\t   dev_set.json  test_set_unlabeled.json\n",
      "act_tag_test.json  README.gdoc\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n4WOO9tvye13"
   },
   "source": [
    "## Dependency installation"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "m03X-0vLyLM0"
   },
   "source": [
    "import json\n",
    "import codecs\n",
    "import pandas as pd\n",
    "\n",
    "import argparse\n",
    "from copy import deepcopy\n",
    "from tqdm import tqdm, trange\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gCt4UVaGNCgI"
   },
   "source": [
    "Install `sentencepiece` for `XLNetTokenizer`"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JmfU0rSbNCzm",
    "outputId": "e6f65bcf-1f41-44a3-d04c-e2b8ea190b92"
   },
   "source": [
    "!pip install sentencepiece\n",
    "\n",
    "import sentencepiece"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (0.1.94)\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aern7KsY01YS"
   },
   "source": [
    "Install `transformers`"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "5hTWa5DGyvQh",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "272b5238-63cd-4901-8aa2-5c824b0f7c8e"
   },
   "source": [
    "!pip install transformers\n",
    "# !pip install transformers==2.0.0\n",
    "from transformers import  AutoConfig, AutoModelForSequenceClassification, AutoTokenizer\n",
    "from transformers import BertModel, RobertaModel\n",
    "from transformers import (AdamW, get_linear_schedule_with_warmup, AutoModelForQuestionAnswering,\n",
    "                          BertConfig, BertForSequenceClassification, BertTokenizer,\n",
    "                          XLNetConfig, XLNetForSequenceClassification, XLNetTokenizer,\n",
    "                          RobertaConfig, RobertaForSequenceClassification, RobertaTokenizer,\n",
    "                          GPT2Config, GPT2ForSequenceClassification, GPT2Tokenizer)"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (4.0.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
      "Requirement already satisfied: tokenizers==0.9.4 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.9.4)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.43)\n",
      "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.7)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.17.0)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.12.5)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qzgCrnTGzNYv"
   },
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "4tv9jG1yzT5m"
   },
   "source": [
    "SEED = 0\n",
    "DEVICE = 'cuda' if torch.cuda.is_available else 'cpu'\n",
    "\n",
    "def set_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "\n",
    "def select_field(feature_list, field_name):\n",
    "    return [\n",
    "        [choice[field_name] for choice in feature.choices_features]\n",
    "        for feature in feature_list\n",
    "    ]\n",
    "\n",
    "\n",
    "def load_model(model='all'):\n",
    "    if model == 'bert':\n",
    "        return BertConfig, BertForSequenceClassification, BertTokenizer\n",
    "    elif model == 'xlnet':\n",
    "        return XLNetConfig, XLNetForSequenceClassification, XLNetTokenizer\n",
    "    elif model == 'roberta':\n",
    "        return RobertaConfig, RobertaForSequenceClassification, RobertaTokenizer\n",
    "    elif model == 'gpt2':\n",
    "        raise NotImplemented\n",
    "        # return GPT2Config, AutoModelForQuestionAnswering, GPT2Tokenizer\n",
    "    raise NotImplemented\n",
    "\n",
    "\n",
    "def load_optimizer(args, model, train_size, learning_rate):\n",
    "    num_training_steps = train_size * args.num_train_epochs\n",
    "    no_decay = ['bias', 'LayerNorm.weight']\n",
    "    optimizer_grouped_parameters = [\n",
    "        {'params': [p for n, p in model.named_parameters()\n",
    "                    if not any(nd in n for nd in no_decay)],\n",
    "         'weight_decay': args.weight_decay},\n",
    "        {'params': [p for n, p in model.named_parameters()\n",
    "                    if any(nd in n for nd in no_decay)],\n",
    "         'weight_decay': 0.0}\n",
    "    ]\n",
    "\n",
    "    optimizer = AdamW(\n",
    "        optimizer_grouped_parameters, lr=learning_rate, eps=args.adam_epsilon)\n",
    "    scheduler = get_linear_schedule_with_warmup(\n",
    "        optimizer, num_warmup_steps=args.warmup_steps, num_training_steps=num_training_steps)\n",
    "\n",
    "    return model, optimizer, scheduler\n",
    "\n",
    "\n",
    "def freeze(model, model_name):\n",
    "    if model_name == 'bert':\n",
    "        for param in model.bert.parameters():\n",
    "            param.requires_grad = False\n",
    "    elif model_name == 'xlnet':\n",
    "        for param in model.xlnet.parameters():\n",
    "            param.requires_grad = False\n",
    "    elif model_name == 'roberta':\n",
    "        for param in model.roberta.parameters():\n",
    "            param.requires_grad = False\n",
    "    elif model_name == 'gpt2':\n",
    "        for param in model.gpt2.parameters():\n",
    "            param.requires_grad = False\n",
    "    return model\n",
    "\n",
    "\n",
    "def get_accuracy(preds, labels, lengths=None, inspect=60):\n",
    "    if inspect:\n",
    "        print('\\nThe first {} predictions'.format(inspect), preds[0:inspect])\n",
    "    if lengths is None:\n",
    "        return (preds == labels).mean()\n",
    "\n",
    "    i, correct = 0, 0\n",
    "    for n in lengths:\n",
    "        pred, label = 1, 1\n",
    "        for p in preds[i:i + n]:\n",
    "            pred *= p\n",
    "        for l in labels[i:i + n]:\n",
    "            label *= l\n",
    "        if pred == label:\n",
    "            correct += 1\n",
    "        i += n\n",
    "    return correct / len(lengths)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tABNFRGMKz6Y"
   },
   "source": [
    "# Benchmark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-ofGNJGHKOK7"
   },
   "source": [
    "## Task Dataset\n",
    "\n",
    "EAT (Everyday Actions in Text) is from the SLED (Situated Language and Embodied Dialogue) group created by Shane Storks. The dataset is in the form of a story of 5 sequential events represented by natural language texts $\\{t_1,t_2,\\cdots,t_5\\}$ respectively. The model aims to identify whether the story is plausible using common sense reasoning and specify at which event the story becomes implausible, if any. Such plausible inference requires the model to have a strong background knowledge and a comprehensive ability to perform common sense reasoning and causal reasoning, since whether an event is plausible in the story is high dependent on the previous events."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "4hOJK9v-KQo2"
   },
   "source": [
    "def load_data(dataset='commonsense_qa', preview=-1):\n",
    "\n",
    "    assert dataset in {'commonsense_qa', 'conv_entail', 'eat'}\n",
    "\n",
    "    if dataset == 'commonsense_qa':\n",
    "        ds = load_dataset('commonsense_qa')\n",
    "\n",
    "        if preview > 0:\n",
    "            print('\\nLoading an example...')\n",
    "            data_tr = ds.data['train']\n",
    "            question = data_tr['question']\n",
    "            choices = data_tr['choices']\n",
    "            answerKey = data_tr['answerKey']\n",
    "            print(question[preview])\n",
    "            for label, text in zip(choices[preview]['label'], choices[preview]['text']):\n",
    "                print(label, text)\n",
    "            print('Ans:', answerKey[preview])\n",
    "\n",
    "    elif dataset == 'conv_entail':\n",
    "        dev_file = '/content/drive/Shareddrives/EECS595-Fall2020/Final_Project_Common/Conversational_Entailment/dev_set.json'\n",
    "        act_file = '/content/drive/Shareddrives/EECS595-Fall2020/Final_Project_Common/Conversational_Entailment/act_tag.json'\n",
    "        test_file = '/content/drive/Shareddrives/EECS595-Fall2020/Final_Project_Common/Conversational_Entailment/test_set_unlabeled.json'\n",
    "        dev_set = codecs.open(dev_file, 'r', encoding='utf-8').read()\n",
    "        test_data = codecs.open(test_file, 'r', encoding='utf-8').read()\n",
    "        ds = json.loads(dev_set), json.loads(test_data)\n",
    "\n",
    "        if preview > 0:\n",
    "            print(ds[0][preview])\n",
    "\n",
    "    else:\n",
    "        file_name = '/content/drive/Shareddrives/EECS595-Fall2020/Final_Project_Common/EAT/eat_train.json'\n",
    "        eat = codecs.open(file_name, 'r', encoding='utf-8').read()\n",
    "        ds = json.loads(eat)\n",
    "\n",
    "        if preview > 0:\n",
    "            print('\\nLoading an example...')\n",
    "            story = ds[preview]['story']\n",
    "            label = ds[preview]['label']\n",
    "            bp = ds[preview]['breakpoint']\n",
    "            for line in story:\n",
    "                print(line)\n",
    "            print(label)\n",
    "            print(bp)\n",
    "\n",
    "    return ds\n",
    "\n",
    "\n",
    "def load_data_frame(preview=True):\n",
    "    \n",
    "    file_name = '/content/drive/Shareddrives/EECS595-Fall2020/Final_Project_Common/EAT/eat_train.json'\n",
    "    df = pd.read_json(file_name)\n",
    "    \n",
    "    if preview:\n",
    "        print(df.head())\n",
    "        print(len(df))\n",
    "\n",
    "    return df"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mRiu77jjKfoH"
   },
   "source": [
    "Run the following code to preview the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "-Er-oLRB6dmw",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "a360c1e5-5a70-4668-cb2e-9d8060ceefb0"
   },
   "source": [
    "ds = load_data(dataset='conv_entail', preview=5)\n",
    "print('\\nDataset size:', len(ds[1]))"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "{'id': 831, 'entailment': '1', 'type': 'belief', 'tag': 'pair', 'items': [{'source': 'SW2020', 'tag': 'dialog', 'items': [{'num': '12', 'speaker': 'B', 'text': \"Uh, uh, however, I, I do, I do like a lot of different forms of music so I switch quite often.  Um, I think I like, I, I'm really particular about the type of music that I listen to.\", 'tag': 'turn'}, {'num': '13', 'speaker': 'A', 'text': 'Uh-huh.', 'tag': 'turn'}, {'num': '14', 'speaker': 'B', 'text': \"But, the, uh, there's such a wide selection, I think I like a lot, I like a little bit of a lot of different types of music.  You know, I, I, I like music that is, that I feel if it is performed correctly or if it's done right, or if the version is done right, I like it [laughter],\", 'tag': 'turn'}]}, {'text': 'SpeakerB likes music that is performed correctly', 'tag': 'h'}]}\n",
      "\n",
      "Dataset size: 355\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8WPeT4QuZKIk",
    "outputId": "df093db0-65f6-494c-b530-abff4767e108"
   },
   "source": [
    "def formulate_conv_entail(data):\n",
    "  premises, hypotheses, labels = [], [], []\n",
    "\n",
    "  # change speakerA to Tom, speakerB to Bob to prevent problems in tokenizing\n",
    "  # change I, you to corresponding speaker\n",
    "  for index, row in enumerate(data):\n",
    "    premise = \"\"\n",
    "    for conversation in row[\"items\"][0][\"items\"]:\n",
    "      speaker = \"Tom\" if conversation[\"speaker\"] == \"A\" else \"Bob\"\n",
    "      another_speaker = \"Bob\" if conversation[\"speaker\"] == \"A\" else \"Tom\"\n",
    "      premise += \" \" + conversation[\"text\"].replace('I ', speaker+\" \").replace('#', '').replace(\"I,\", speaker+\",\").replace(\"you \", another_speaker+\" \").replace(\"you,\", another_speaker+\",\")\n",
    "    hypothesis = row[\"items\"][1][\"text\"].replace(\"SpeakerA\", \"Tom\").replace(\"SpeakerB\", \"Bob\").replace('#', '')\n",
    "    premises.append(premise)\n",
    "    hypotheses.append(hypothesis)\n",
    "    labels.append(int(row['entailment']))\n",
    "\n",
    "  return premises, hypotheses, labels\n",
    "\n",
    "\n",
    "premises, hypotheses, labels = formulate_conv_entail(ds[0])\n",
    "\n",
    "print(\"Preview of the data: \")\n",
    "print(\"Premise:\", premises[0])\n",
    "print(\"Hypothesis:\", hypotheses[0])\n",
    "print(\"Label:\", labels[0])\n",
    "\n",
    "def get_conv_detail_testdata(data):\n",
    "  premises, hypotheses = [], []\n",
    "\n",
    "  # change speakerA to Tom, speakerB to Bob to prevent problems in tokenizing\n",
    "  # change I, you to corresponding speaker\n",
    "  for index, row in enumerate(data):\n",
    "    premise = \"\"\n",
    "    for conversation in row[\"items\"][0][\"items\"]:\n",
    "      speaker = \"Tom\" if conversation[\"speaker\"] == \"A\" else \"Bob\"\n",
    "      another_speaker = \"Bob\" if conversation[\"speaker\"] == \"A\" else \"Tom\"\n",
    "      premise += \" \" + conversation[\"text\"].replace('I ', speaker+\" \").replace('#', '').replace(\"I,\", speaker+\",\").replace(\"you \", another_speaker+\" \").replace(\"you,\", another_speaker+\",\")\n",
    "    hypothesis = row[\"items\"][1][\"text\"].replace(\"SpeakerA\", \"Tom\").replace(\"SpeakerB\", \"Bob\").replace('#', '')\n",
    "    premises.append(premise)\n",
    "    hypotheses.append(hypothesis)\n",
    "\n",
    "  return premises, hypotheses\n"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Preview of the data: \n",
      "Premise:  Um, mostly what Bob do, Bob do do some crafts like it mentioned in the thing, and then Bob, Bob read a lot.\n",
      "Hypothesis: Bob likes to read\n",
      "Label: 1\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z1xpXY-QttAR",
    "outputId": "4f470cb4-17dc-41c9-8f6e-62a3651f3ef7"
   },
   "source": [
    "print(\"Preview of the data: \")\n",
    "print(\"Premise:\", premises[301])\n",
    "print(\"Hypothesis:\", hypotheses[301])\n",
    "print(\"Label:\", labels[301])\n"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Preview of the data: \n",
      "Premise:  And, uh, it was about, the, the piece of music, the piece of music was about, Bob think about forty or fifty years old.  And, it was incredible, Bob mean, the parallel, Tom know, between it and rap. Right. And, um, Tom, Tom listen a lot, if Tom, if Tom hear a lot of old gospel, uh, uh, especially well, the black gospel.  You know, Tom will, Tom know, Tom can really pick it up.  Bob mean,\n",
      "Hypothesis: Tom thinks that Bob listens to a lot of black gospel\n",
      "Label: 0\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C0Vq_hBp7PNB"
   },
   "source": [
    "Get the length of all the messages in the train set to choose appropriate a padding length."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "HMBZjpF27Jyg",
    "outputId": "7019241d-ac7c-463b-d013-b47139f778cb"
   },
   "source": [
    "train_text = [premises[i] + ' ' + hypotheses[i] for i in range(len(premises))]\n",
    "seq_len = [len(i.split()) for i in train_text]\n",
    "pd.Series(seq_len).hist(bins = 30)"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f2ff153bf98>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "execution_count": 13
    },
    {
     "output_type": "display_data",
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAD4CAYAAAD1jb0+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAOYElEQVR4nO3db4xc5XXH8e8pDglhKYYQrSyDuk6DUkVYTWFFqYjQbuifBFc1lVCEhFK7ovKbkrqtI2XTvEheNKqpRCIqRZXcguRWKJvUIQLVog2lbKO+wI2XEAy4FIeYBIvYjWpIFqEmbk9f7LXYLrs7d//MzpzZ70eydu6dZ2bO4Vl+uvPMvbORmUiS6vmZXhcgSVoZA1ySijLAJakoA1ySijLAJamoTev5YldccUWOjIx0HPf6669z8cUXd7+gHtsIfdrjYNgIPUL/9jk9Pf3DzHz3/P3rGuAjIyMcPXq047ipqSnGxsa6X1CPbYQ+7XEwbIQeoX/7jIiXFtrvEookFWWAS1JRBrgkFWWAS1JRBrgkFWWAS1JRBrgkFWWAS1JRBrgkFbWuV2L2k5GJw63Gndy/o8uVSNLKeAQuSUUZ4JJUlAEuSUUZ4JJUlAEuSUUZ4JJUlAEuSUUZ4JJUlAEuSUUZ4JJUlAEuSUUZ4JJUlAEuSUUZ4JJUlAEuSUUZ4JJUlAEuSUUZ4JJUlAEuSUUZ4JJUlAEuSUW1CvCI+KOIeDYinomIL0XEOyJiW0QciYgTEfHliLiw28VKkt7UMcAjYivwB8BoZl4DXADcDtwNfCEz3wucBe7sZqGSpP+v7RLKJuCiiNgEvBN4BfgQcKi5/yBw69qXJ0laTGRm50ERe4HPAW8AXwf2Ak80R99ExFXAI80R+vzH7gH2AAwPD183OTnZ8fVmZmYYGhpaRhvLd+zUa63Gbd96addqWI8+e80eB8NG6BH6t8/x8fHpzBydv39TpwdGxGXATmAb8Crwd8CH275wZh4ADgCMjo7m2NhYx8dMTU3RZtxq7J443GrcyTu6V8d69Nlr9jgYNkKPUK/PNksovwp8NzP/MzN/CjwI3AhsbpZUAK4ETnWpRknSAtoE+PeAGyLinRERwM3Ac8DjwG3NmF3AQ90pUZK0kI5LKJl5JCIOAU8C54BvMbskchiYjIg/bfbd181CKxhpuyyzf0eXK5G0EXQMcIDM/AzwmXm7XwSuX/OKJEmteCWmJBVlgEtSUQa4JBVlgEtSUQa4JBXV6iyUjaztqYGStN48ApekogxwSSrKAJekogxwSSrKAJekogxwSSrKAJekogxwSSrKAJekogxwSSrKAJekogxwSSrKAJekogxwSSrKAJekogxwSSrKAJekogxwSSrKAJekogxwSSrKAJekogxwSSrKAJekogxwSSrKAJekogxwSSrKAJekogxwSSrKAJekogxwSSqqVYBHxOaIOBQR/x4RxyPiVyLi8oh4NCJeaH5e1u1iJUlvansEfi/wD5n5C8AvAseBCeCxzLwaeKzZliStk44BHhGXAjcB9wFk5k8y81VgJ3CwGXYQuLVbRUqS3ioyc+kBER8ADgDPMXv0PQ3sBU5l5uZmTABnz2/Pe/weYA/A8PDwdZOTkx2LmpmZYWhoaHmdLNOxU6919fmXsn3rpcD69Nlr9jgYNkKP0L99jo+PT2fm6Pz9bQJ8FHgCuDEzj0TEvcCPgI/PDeyIOJuZS66Dj46O5tGjRzsWOzU1xdjYWMdxqzEycbirz7+Uk/t3AOvTZ6/Z42DYCD1C//YZEQsGeJs18JeBlzPzSLN9CLgWOB0RW5on3wKcWatiJUmddQzwzPwB8P2IeF+z62Zml1MeBnY1+3YBD3WlQknSgja1HPdx4IGIuBB4EfhdZsP/KxFxJ/AS8NHulChJWkirAM/Mp4C3rL8wezQuSeoBr8SUpKIMcEkqygCXpKIMcEkqygCXpKIMcEkqygCXpKIMcEkqygCXpKIMcEkqygCXpKIMcEkqygCXpKIMcEkqygCXpKIMcEkqygCXpKIMcEkqygCXpKIMcEkqygCXpKIMcEkqalOvC9iIRiYOA7Bv+zl2N7cXcnL/jvUqSVJBHoFLUlEGuCQVZYBLUlEGuCQVZYBLUlEGuCQVZYBLUlEGuCQVZYBLUlEGuCQVZYBLUlEGuCQVZYBLUlEGuCQV1TrAI+KCiPhWRPx9s70tIo5ExImI+HJEXNi9MiVJ8y3nCHwvcHzO9t3AFzLzvcBZ4M61LEyStLRWAR4RVwI7gL9utgP4EHCoGXIQuLUbBUqSFhaZ2XlQxCHgz4BLgE8Au4EnmqNvIuIq4JHMvGaBx+4B9gAMDw9fNzk52fH1ZmZmGBoaat/FChw79VpXn7+N4Yvg9Burf57tWy9d/ZN0yXrMZa/Z4+Do1z7Hx8enM3N0/v6Of1ItIn4TOJOZ0xExttwXzswDwAGA0dHRHBvr/BRTU1O0GbcaS/0ps/Wyb/s57jm2+r9qd/KOsdUX0yXrMZe9Zo+Do1qfbdLjRuC3IuIW4B3AzwL3ApsjYlNmngOuBE51r0xJ0nwd18Az81OZeWVmjgC3A/+cmXcAjwO3NcN2AQ91rUpJ0lus5jzwTwJ/HBEngHcB961NSZKkNpa1AJuZU8BUc/tF4Pq1L0mS1IZXYkpSUQa4JBVlgEtSUQa4JBVlgEtSUQa4JBVlgEtSUav/Ig713EjL73U5uX9HlyuRtJ48ApekogxwSSrKAJekogxwSSpq4D7EbPuBniRV5xG4JBU1cEfgWpynG0qDxSNwSSrKAJekogxwSSrKAJekogxwSSrKAJekogxwSSrKAJekogxwSSrKAJekogxwSSrKAJekogxwSSrKAJekogxwSSrKAJekogxwSSrKAJekogxwSSrKAJekogxwSSqqY4BHxFUR8XhEPBcRz0bE3mb/5RHxaES80Py8rPvlSpLO29RizDlgX2Y+GRGXANMR8SiwG3gsM/dHxAQwAXyye6VqvYxMHG417uT+HV2uRNJSOh6BZ+Yrmflkc/vHwHFgK7ATONgMOwjc2q0iJUlvFZnZfnDECPAN4Brge5m5udkfwNnz2/MeswfYAzA8PHzd5ORkx9eZmZlhaGiodV1zHTv12ooe1wvDF8HpN3pdxcpt33ppxzGrmcsq7HFw9Guf4+Pj05k5On9/6wCPiCHgX4DPZeaDEfHq3MCOiLOZueQ6+OjoaB49erTja01NTTE2Ntaqrvnavv3vB/u2n+OeY21WsfpTmyWU1cxlFfY4OPq1z4hYMMBbnYUSEW8Dvgo8kJkPNrtPR8SW5v4twJm1KlaS1Fmbs1ACuA84npmfn3PXw8Cu5vYu4KG1L0+StJg2799vBD4GHIuIp5p9fwLsB74SEXcCLwEf7U6JkqSFdAzwzPxXIBa5++a1LUeS1JZXYkpSUQa4JBVlgEtSUQa4JBVlgEtSUQa4JBVlgEtSUQa4JBVV95uU1HNtvjhs3/Zz7J447HeHS13gEbgkFWWAS1JRBrgkFeUauPqKf49Tas8jcEkqygCXpKIMcEkqygCXpKIMcEkqygCXpKI8jVAlebqh5BG4JJVlgEtSUWWWUNq+ZVZ/cv6ktecRuCQVZYBLUlEGuCQVZYBLUlEGuCQVVeYsFKmbvDBIFXkELklFGeCSVJQBLklFGeCSVJQBLklFGeCSVJSnEWqgrfWXaC30fPu2n2P3Kl6n7amJnuqo+TwCl6SiVhXgEfHhiHg+Ik5ExMRaFSVJ6mzFSygRcQHwReDXgJeBb0bEw5n53FoVJ2n5uvHd66tdJlqpfl8O6vWy1mqOwK8HTmTmi5n5E2AS2Lk2ZUmSOonMXNkDI24DPpyZv9dsfwz45cy8a964PcCeZvN9wPMtnv4K4IcrKqyWjdCnPQ6GjdAj9G+fP5eZ756/s+tnoWTmAeDAch4TEUczc7RLJfWNjdCnPQ6GjdAj1OtzNUsop4Cr5mxf2eyTJK2D1QT4N4GrI2JbRFwI3A48vDZlSZI6WfESSmaei4i7gH8ELgDuz8xn16iuZS25FLYR+rTHwbAReoRifa74Q0xJUm95JaYkFWWAS1JRfRfgg3p5fkScjIhjEfFURBxt9l0eEY9GxAvNz8t6XedyRcT9EXEmIp6Zs2/BvmLWXzRz+3REXNu7yttbpMfPRsSpZj6fiohb5tz3qabH5yPiN3pT9fJExFUR8XhEPBcRz0bE3mb/wMzlEj3WncvM7Jt/zH4Y+h3gPcCFwLeB9/e6rjXq7SRwxbx9fw5MNLcngLt7XecK+roJuBZ4plNfwC3AI0AANwBHel3/Knr8LPCJBca+v/m9fTuwrfl9vqDXPbTocQtwbXP7EuA/ml4GZi6X6LHsXPbbEfhGuzx/J3CwuX0QuLWHtaxIZn4D+K95uxfrayfwNznrCWBzRGxZn0pXbpEeF7MTmMzM/87M7wInmP297muZ+UpmPtnc/jFwHNjKAM3lEj0upu/nst8CfCvw/TnbL7P0f+BKEvh6REw3Xy8AMJyZrzS3fwAM96a0NbdYX4M2v3c1ywf3z1n+Kt9jRIwAvwQcYUDncl6PUHQu+y3AB9kHM/Na4CPA70fETXPvzNn3bAN3Tueg9gX8JfDzwAeAV4B7elvO2oiIIeCrwB9m5o/m3jcoc7lAj2Xnst8CfGAvz8/MU83PM8DXmH0rdvr8287m55neVbimFutrYOY3M09n5v9k5v8Cf8Wbb63L9hgRb2M22B7IzAeb3QM1lwv1WHku+y3AB/Ly/Ii4OCIuOX8b+HXgGWZ729UM2wU81JsK19xifT0M/E5zBsMNwGtz3p6XMm+997eZnU+Y7fH2iHh7RGwDrgb+bb3rW66ICOA+4Hhmfn7OXQMzl4v1WHoue/0p6gKf/N7C7KfD3wE+3et61qin9zD7afa3gWfP9wW8C3gMeAH4J+DyXte6gt6+xOzbzp8yu0Z452J9MXvGwhebuT0GjPa6/lX0+LdND08z+z/6ljnjP930+DzwkV7X37LHDzK7PPI08FTz75ZBmssleiw7l15KL0lF9dsSiiSpJQNckooywCWpKANckooywCWpKANckooywCWpqP8DCVpMAFO+J8wAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": [],
      "needs_background": "light"
     }
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rIxGTEYezc1L"
   },
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "HS5CDydVzfAB"
   },
   "source": [
    "MAXLENGTH = 200\n",
    "\n",
    "class ConvEntailProcessor():\n",
    "    def __init__(self, tokenizer, args=None):\n",
    "\n",
    "        test_size = 0.15\n",
    "        if args is not None:\n",
    "            test_size = args.test_size\n",
    "\n",
    "        self.tokenizer = tokenizer\n",
    "        self.double_sep = 'roberta' in tokenizer.name_or_path\n",
    "        self.cls_token = tokenizer.cls_token\n",
    "        self.sep_token = tokenizer.sep_token\n",
    "\n",
    "        all_premises, all_hypotheses, all_labels = formulate_conv_entail(load_data(dataset='conv_entail')[0])\n",
    "        self.train_premises, self.val_premises, self.train_hypotheses, self.val_hypotheses, \\\n",
    "        self.train_labels, self.val_labels = train_test_split(all_premises, all_hypotheses, \n",
    "                                                               all_labels, random_state=SEED, test_size=test_size)\n",
    "        self.test_premises, self.test_hypotheses = get_conv_detail_testdata(load_data(dataset='conv_entail')[1])\n",
    "        \n",
    "    def truncate_seq_pair(self, token_a, token_b, max_len=MAXLENGTH-3):\n",
    "        \"\"\"\n",
    "        Truncates a sequence pair in place to the maximum length.\n",
    "\n",
    "        This is a simple heuristic which will always truncate the longer sequence one token at a time.\n",
    "        This makes more sense than truncating an equal percent of tokens from each,\n",
    "        since if one sequence is very short then each token that's truncated\n",
    "        likely contains more information than a longer sequence.\n",
    "\n",
    "        However, since we'd better not to remove tokens of options and questions,\n",
    "        you can choose to use a bigger length or only pop from context\n",
    "        \"\"\"\n",
    "\n",
    "        while True:\n",
    "            total_length = len(token_a) + len(token_b)\n",
    "            if total_length <= max_len:\n",
    "                break\n",
    "            if len(token_a) > len(token_b):\n",
    "                token_a.pop()\n",
    "            else:\n",
    "                warning = 'Attention! you are removing from token_b (swag task is ok). ' \\\n",
    "                          'If you are training ARC and RACE (you are popping question + options), ' \\\n",
    "                          'you need to try to use a bigger max seq length!'\n",
    "                print(warning)\n",
    "                token_b.pop()\n",
    "\n",
    "    def tokenize_and_encode(self, prev, next, max_len=MAXLENGTH):\n",
    "        \"\"\"\n",
    "        Tokenize all of the sentences and map the tokens to their word IDs.\n",
    "        Max is 512 if using BERT-based models, higher for longformer (2000+)\n",
    "        \"\"\"\n",
    "\n",
    "        num_seps = 1\n",
    "        extra_tokens = 3\n",
    "        if self.double_sep:\n",
    "            num_seps += 1\n",
    "            extra_tokens += 1\n",
    "\n",
    "        token_a = self.tokenizer.tokenize(prev)\n",
    "        token_b = self.tokenizer.tokenize(next)\n",
    "        self.truncate_seq_pair(token_a, token_b, max_len-extra_tokens)\n",
    "\n",
    "        token_a = [self.cls_token] + token_a + ([self.sep_token] * num_seps)\n",
    "        token_type_ids = [0] * len(token_a)\n",
    "        token_b = token_b + [self.sep_token]\n",
    "        token_type_ids += [1] * len(token_b)\n",
    "        tokens = token_a + token_b\n",
    "\n",
    "        input_ids = self.tokenizer.convert_tokens_to_ids(tokens)\n",
    "        mask = [1] * len(input_ids)\n",
    "\n",
    "        padding_length = max_len - len(input_ids)\n",
    "        input_ids += ([0] * padding_length)\n",
    "        mask += ([0] * padding_length)\n",
    "        token_type_ids += ([0] * padding_length)\n",
    "\n",
    "        assert len(input_ids) == max_len\n",
    "        assert len(token_type_ids) == max_len\n",
    "        assert len(mask) == max_len\n",
    "            \n",
    "        return input_ids, token_type_ids, mask\n",
    "\n",
    "    def load_features(self, split='train'):\n",
    "\n",
    "        if split == 'train':\n",
    "            pre, hypo, labels = self.train_premises, self.train_hypotheses, self.train_labels\n",
    "        elif split == 'val':\n",
    "            pre, hypo, labels = self.val_premises, self.val_hypotheses, self.val_labels\n",
    "        else:\n",
    "            pre, hypo = self.test_premises, self.test_hypotheses\n",
    "            seqs, segs, masks, lengths = [], [], [], []\n",
    "            for prev, next in zip(pre, hypo):\n",
    "              seq, seg, mask = self.tokenize_and_encode(prev, next)\n",
    "              seqs.append(seq)\n",
    "              segs.append(seg)\n",
    "              masks.append(mask)\n",
    "\n",
    "            seqs = torch.tensor(seqs)\n",
    "            segs = torch.tensor(segs)\n",
    "            masks = torch.tensor(masks)\n",
    "\n",
    "            dataset = TensorDataset(seqs, masks, segs)\n",
    "            return dataset, lengths\n",
    "            \n",
    "\n",
    "        seqs, segs, masks, lengths = [], [], [], []\n",
    "        for prev, next in zip(pre, hypo):\n",
    "          seq, seg, mask = self.tokenize_and_encode(prev, next)\n",
    "          seqs.append(seq)\n",
    "          segs.append(seg)\n",
    "          masks.append(mask)\n",
    "\n",
    "        labels = torch.tensor(labels)\n",
    "        seqs = torch.tensor(seqs)\n",
    "        segs = torch.tensor(segs)\n",
    "        masks = torch.tensor(masks)\n",
    "\n",
    "        dataset = TensorDataset(seqs, masks, segs, labels)\n",
    "\n",
    "        return dataset, lengths"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "v7ORg7HJqjWO"
   },
   "source": [
    "# tokenizer_bert = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
    "# tokenizer_rbt = RobertaTokenizer.from_pretrained('roberta-base', do_lower_case=True)\n",
    "\n",
    "# processor_tmp = EATProcessor(tokenizer_bert)\n",
    "# prev = 'John grabbed the ladder and put it in his truck.'\n",
    "# next = 'John put a drill and rope in the bucket and also put that in this truck.'\n",
    "# seq, seg, mask = processor_tmp.tokenize_and_encode(prev, next)\n",
    "# print(prev, next)\n",
    "# print(seq)\n",
    "# print(seg)\n",
    "# print(mask)\n",
    "# print(len(seq), len(seg), len(mask))\n",
    "\n",
    "# processor_tmp = EATProcessor(tokenizer_rbt)\n",
    "# prev = 'John grabbed the ladder and put it in his truck.'\n",
    "# next = 'John put a drill and rope in the bucket and also put that in this truck.'\n",
    "# seq, seg, mask = processor_tmp.tokenize_and_encode(prev, next)\n",
    "# print(prev, next)\n",
    "# print(seq)\n",
    "# print(seg)\n",
    "# print(mask)\n",
    "# print(len(seq), len(seg), len(mask))"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gy237KUt4bfZ"
   },
   "source": [
    "## Knowledge Dataset\n",
    "\n",
    "PIQA\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ApoNGj8A4gYY",
    "outputId": "21337785-fa91-4fdc-ba2c-85537066b001"
   },
   "source": [
    "!wget https://storage.googleapis.com/ai2-mosaic/public/physicaliqa/physicaliqa-train-dev.zip\n",
    "!unzip physicaliqa-train-dev.zip"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "--2020-12-15 07:13:32--  https://storage.googleapis.com/ai2-mosaic/public/physicaliqa/physicaliqa-train-dev.zip\n",
      "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.20.128, 74.125.28.128, 74.125.142.128, ...\n",
      "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.20.128|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1824009 (1.7M) [application/zip]\n",
      "Saving to: ‘physicaliqa-train-dev.zip’\n",
      "\n",
      "\r          physicali   0%[                    ]       0  --.-KB/s               \rphysicaliqa-train-d 100%[===================>]   1.74M  --.-KB/s    in 0.01s   \n",
      "\n",
      "2020-12-15 07:13:32 (155 MB/s) - ‘physicaliqa-train-dev.zip’ saved [1824009/1824009]\n",
      "\n",
      "Archive:  physicaliqa-train-dev.zip\n",
      "replace physicaliqa-train-dev/train.jsonl? [y]es, [n]o, [A]ll, [N]one, [r]ename: A\n",
      "  inflating: physicaliqa-train-dev/train.jsonl  \n",
      "  inflating: physicaliqa-train-dev/.DS_Store  \n",
      "  inflating: __MACOSX/physicaliqa-train-dev/._.DS_Store  \n",
      "  inflating: physicaliqa-train-dev/train-labels.lst  \n",
      "  inflating: physicaliqa-train-dev/dev-labels.lst  \n",
      "  inflating: physicaliqa-train-dev/dev.jsonl  \n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "ScP8KsAt5Mf0"
   },
   "source": [
    "def load_piqa(preview=False):\n",
    "    \n",
    "    file_name = 'physicaliqa-train-dev/train.jsonl'\n",
    "    df = pd.read_json(path_or_buf=file_name, lines=True)\n",
    "    with open('physicaliqa-train-dev/train-labels.lst') as f:\n",
    "      labels = [int(i) for i in list(f.read().splitlines())]\n",
    "    df['labels'] = labels\n",
    "\n",
    "    if preview:\n",
    "        print(len(df))\n",
    "        row = df.iloc[[preview]]\n",
    "        print(row['goal'])\n",
    "        print(row['sol1'])\n",
    "        print(row['sol2'])\n",
    "        print(row['labels'])\n",
    "    return df"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "RdAjdixUfq9b",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "09cc95dd-afe7-4249-ad8c-f8b0155f3836"
   },
   "source": [
    "df = load_piqa(preview=1)"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "16113\n",
      "1    To permanently attach metal legs to a chair, y...\n",
      "Name: goal, dtype: object\n",
      "1    Weld the metal together to get it to stay firm...\n",
      "Name: sol1, dtype: object\n",
      "1    Nail the metal together to get it to stay firm...\n",
      "Name: sol2, dtype: object\n",
      "1    0\n",
      "Name: labels, dtype: int64\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oXZR0GqLb0n3"
   },
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Sxw1c_kc5pWY"
   },
   "source": [
    "class PIQAProcessor():\n",
    "    \"\"\"\n",
    "    Load the processed SWAG dataset\n",
    "    max(size) = 73546\n",
    "    \"\"\"\n",
    "    def __init__(self, tokenizer, args=None):\n",
    "        self.test_size = 0.15\n",
    "        if args is not None:\n",
    "            self.test_size = args.test_size\n",
    "\n",
    "        self.tokenizer = tokenizer\n",
    "        self.double_sep = 'roberta' in tokenizer.name_or_path\n",
    "        self.cls_token = tokenizer.cls_token\n",
    "        self.sep_token = tokenizer.sep_token\n",
    "\n",
    "        self.df = load_piqa()\n",
    "    \n",
    "    def truncate_seq_pair(self, token_a, token_b, max_len=MAXLENGTH-3):\n",
    "        \"\"\"\n",
    "        Truncates a sequence pair in place to the maximum length.\n",
    "\n",
    "        This is a simple heuristic which will always truncate the longer sequence one token at a time.\n",
    "        This makes more sense than truncating an equal percent of tokens from each,\n",
    "        since if one sequence is very short then each token that's truncated\n",
    "        likely contains more information than a longer sequence.\n",
    "\n",
    "        However, since we'd better not to remove tokens of options and questions,\n",
    "        you can choose to use a bigger length or only pop from context\n",
    "        \"\"\"\n",
    "\n",
    "        while True:\n",
    "            total_length = len(token_a) + len(token_b)\n",
    "            if total_length <= max_len:\n",
    "                break\n",
    "            if len(token_a) > len(token_b):\n",
    "                token_a.pop()\n",
    "            else:\n",
    "                warning = 'Attention! you are removing from token_b (swag task is ok). ' \\\n",
    "                          'If you are training ARC and RACE (you are popping question + options), ' \\\n",
    "                          'you need to try to use a bigger max seq length!'\n",
    "                print(warning)\n",
    "                token_b.pop()\n",
    "\n",
    "    def tokenize_and_encode(self, prev, next, max_len=MAXLENGTH):\n",
    "        \"\"\"\n",
    "        Tokenize all of the sentences and map the tokens to their word IDs.\n",
    "        Max is 512 if using BERT-based models, higher for longformer (2000+)\n",
    "        \"\"\"\n",
    "\n",
    "        num_seps = 1\n",
    "        extra_tokens = 3\n",
    "        if self.double_sep:\n",
    "            num_seps += 1\n",
    "            extra_tokens += 1\n",
    "\n",
    "        token_a = self.tokenizer.tokenize(prev)\n",
    "        token_b = self.tokenizer.tokenize(next)\n",
    "        self.truncate_seq_pair(token_a, token_b, max_len-extra_tokens)\n",
    "\n",
    "        token_a = [self.cls_token] + token_a + ([self.sep_token] * num_seps)  \n",
    "        token_type_ids = [0] * len(token_a)\n",
    "        token_b = token_b + [self.sep_token]\n",
    "        token_type_ids += [1] * len(token_b)\n",
    "        tokens = token_a + token_b\n",
    "\n",
    "        input_ids = self.tokenizer.convert_tokens_to_ids(tokens)\n",
    "        mask = [1] * len(input_ids)\n",
    "\n",
    "        padding_length = max_len - len(input_ids)\n",
    "        input_ids += ([0] * padding_length)\n",
    "        mask += ([0] * padding_length)\n",
    "        token_type_ids += ([0] * padding_length)\n",
    "\n",
    "        assert len(input_ids) == max_len\n",
    "        assert len(token_type_ids) == max_len\n",
    "        assert len(mask) == max_len\n",
    "            \n",
    "        return input_ids, token_type_ids, mask\n",
    "\n",
    "    def load_features(self, size=16113):\n",
    "\n",
    "        print(\"Creating features from dataset...\")\n",
    "        labels, seqs, segs, masks = [], [], [], []\n",
    "        for row in df.iterrows():\n",
    "\n",
    "            label = row[1]['labels']\n",
    "            goal = row[1]['goal']\n",
    "            sol1 = row[1]['sol1']\n",
    "            sol2 = row[1]['sol2']\n",
    "\n",
    "            if label == 0:\n",
    "                seq, seg, mask = self.tokenize_and_encode(goal, sol1)\n",
    "                seqs.append(seq)\n",
    "                segs.append(seg)\n",
    "                masks.append(mask)\n",
    "                labels.append(1)\n",
    "\n",
    "                seq, seg, mask = self.tokenize_and_encode(goal, sol2)\n",
    "                seqs.append(seq)\n",
    "                segs.append(seg)\n",
    "                masks.append(mask)\n",
    "                labels.append(0)\n",
    "            else:\n",
    "                seq, seg, mask = self.tokenize_and_encode(goal, sol1)\n",
    "                seqs.append(seq)\n",
    "                segs.append(seg)\n",
    "                masks.append(mask)\n",
    "                labels.append(0)\n",
    "\n",
    "                seq, seg, mask = self.tokenize_and_encode(goal, sol2)\n",
    "                seqs.append(seq)\n",
    "                segs.append(seg)\n",
    "                masks.append(mask)\n",
    "                labels.append(1)\n",
    "                        \n",
    "            size -= 1\n",
    "            if size == 0:\n",
    "                break\n",
    "\n",
    "        train_seq, val_seq, train_seg, val_seg, train_mask, val_mask, train_labels, val_labels = train_test_split(\n",
    "            seqs, segs, masks, labels, random_state=SEED, test_size=self.test_size, stratify=labels)\n",
    "        \n",
    "        train_seq = torch.tensor(train_seq)\n",
    "        val_seq = torch.tensor(val_seq)\n",
    "        train_seg = torch.tensor(train_seg)\n",
    "        val_seg = torch.tensor(val_seg)\n",
    "        train_mask = torch.tensor(train_mask)\n",
    "        val_mask = torch.tensor(val_mask)\n",
    "        train_labels = torch.tensor(train_labels)\n",
    "        train_y = torch.tensor(train_labels)\n",
    "        val_y = torch.tensor(val_labels)\n",
    "\n",
    "        train_data = TensorDataset(train_seq, train_mask, train_seg, train_y)\n",
    "        val_data = TensorDataset(val_seq, val_mask, val_seg, val_y)\n",
    "\n",
    "        return train_data, val_data\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "92jFJkifK6Cf"
   },
   "source": [
    "# Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sQ0BLRx-zmep"
   },
   "source": [
    "## Pre-trained Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AJKT-_9boL-c"
   },
   "source": [
    "Self-designed model for flexibility."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Ew2T52OZq0tD"
   },
   "source": [
    "class MyBertClassifier(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, model_name='bert-base-uncased', num_labels=1, dropout_rate=0.2, freeze=False):\n",
    "        super(MyBertClassifier, self).__init__()\n",
    "        \n",
    "        if num_labels == 1:\n",
    "            self.loss_fct = torch.nn.BCEWithLogitsLoss()\n",
    "        else:\n",
    "            self.loss_fct = torch.nn.CrossEntropyLoss()\n",
    "        self.bert = BertModel.from_pretrained(model_name)\n",
    "        self.d1 = torch.nn.Dropout(dropout_rate)\n",
    "        self.l1 = torch.nn.Linear(self.num_embed(model_name), 64)\n",
    "        self.bn1 = torch.nn.LayerNorm(64)\n",
    "        self.d2 = torch.nn.Dropout(dropout_rate)\n",
    "        self.l2 = torch.nn.Linear(64, num_labels)\n",
    "\n",
    "        if freeze:\n",
    "            for param in self.bert.parameters():\n",
    "                param.requires_grad = False\n",
    "\n",
    "    def num_embed(self, model_name):\n",
    "        embedding_size = {\n",
    "            'bert-base-uncased': 768,\n",
    "            'bert-large-uncased': 1024\n",
    "        }\n",
    "        return embedding_size[model_name]\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, token_type_ids, labels=None):\n",
    "\n",
    "        out = self.bert(input_ids=input_ids, \n",
    "                        attention_mask=attention_mask, \n",
    "                        token_type_ids=token_type_ids)\n",
    "        x = out.pooler_output\n",
    "        x = self.d1(x)\n",
    "        x = self.l1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = torch.nn.Tanh()(x)\n",
    "        x = self.d2(x)\n",
    "        x = self.l2(x)\n",
    "\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            # x = np.argmax(x, axis=1)\n",
    "            loss = self.loss_fct(x.flatten(), labels.float())\n",
    "        \n",
    "        return loss, x\n",
    "\n",
    "\n",
    "class MyRobertaClassifier(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, model_name='roberta-base', num_labels=2, dropout_rate=0.2, freeze=False):\n",
    "        super(MyRobertaClassifier, self).__init__()\n",
    "        \n",
    "        if num_labels == 1:\n",
    "            self.loss_fct = torch.nn.BCEWithLogitsLoss()\n",
    "        else:\n",
    "            self.loss_fct = torch.nn.CrossEntropyLoss(torch.tensor([0.5,0.5],dtype=torch.float).to(DEVICE))\n",
    "        self.roberta = RobertaModel.from_pretrained(model_name)\n",
    "        self.d1 = torch.nn.Dropout(dropout_rate)\n",
    "        self.l1 = torch.nn.Linear(self.num_embed(model_name), 64)\n",
    "        self.bn1 = torch.nn.LayerNorm(64)\n",
    "        self.d2 = torch.nn.Dropout(dropout_rate)\n",
    "        self.l2 = torch.nn.Linear(64, num_labels)\n",
    "\n",
    "        if freeze:\n",
    "            for param in self.roberta.parameters():\n",
    "                param.requires_grad = False\n",
    "\n",
    "    def num_embed(self, model_name):\n",
    "        embedding_size = {\n",
    "            'roberta-base': 768,\n",
    "            'roberta-large': 1024,\n",
    "        }\n",
    "        return embedding_size[model_name]\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, token_type_ids, labels=None):\n",
    "\n",
    "        out = self.roberta(input_ids=input_ids, \n",
    "                           attention_mask=attention_mask, \n",
    "                           token_type_ids=None)\n",
    "        x = out.pooler_output\n",
    "        x = self.d1(x)\n",
    "        x = self.l1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = torch.nn.Tanh()(x)\n",
    "        x = self.d2(x)\n",
    "        x = self.l2(x)\n",
    "        \n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            # x = np.argmax(x, axis=1)\n",
    "            loss = self.loss_fct(x, labels)\n",
    "        \n",
    "        return loss, x\n",
    "\n",
    "\n",
    "class myRoberta_mnliClassifier(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, pretrained_model, num_labels=2, freeze=False):\n",
    "        super(myRoberta_mnliClassifier, self).__init__()\n",
    "        \n",
    "        if num_labels == 1:\n",
    "            self.loss_fct = torch.nn.BCEWithLogitsLoss()\n",
    "        else:\n",
    "            self.loss_fct = torch.nn.NLLLoss(torch.tensor([0.55,0.45],dtype=torch.float).to(DEVICE))\n",
    "        self.roberta = pretrained_model\n",
    "        self.softmax = torch.nn.Softmax(dim=1)\n",
    "\n",
    "        if freeze:\n",
    "            for param in self.roberta.parameters():\n",
    "                param.requires_grad = False\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, token_type_ids, labels=None):\n",
    "\n",
    "        out = self.roberta(input_ids=input_ids, \n",
    "                           attention_mask=attention_mask, \n",
    "                           token_type_ids=None,\n",
    "                           labels=labels)\n",
    "        \n",
    "        x = out[0] if labels is None else out[1]\n",
    "        x = self.softmax(x)\n",
    "        x = torch.stack((1-x[:,2],x[:,2]),dim=1)\n",
    "        x = torch.log(x)\n",
    "        \n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            # x = np.argmax(x, axis=1)\n",
    "            loss = self.loss_fct(x, labels)\n",
    "        \n",
    "        return loss, x"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QWb1PKeZztGS"
   },
   "source": [
    "## Runtime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c9Sn_8byoIR2"
   },
   "source": [
    "Training and evaluation functions."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "V3xQdSF8zl1q"
   },
   "source": [
    "def fine_tune(args, model, tokenizer):\n",
    "\n",
    "    processor = PIQAProcessor(tokenizer, args)\n",
    "    dataset_tr, dataset_val = processor.load_features(size=args.pretrain_size)\n",
    "\n",
    "    print('\\n Loading training dataset')\n",
    "    sampler_tr = RandomSampler(dataset_tr)\n",
    "    dataloader_tr = DataLoader(dataset_tr, sampler=sampler_tr, batch_size=args.batch_size)\n",
    "\n",
    "    print('\\n Loading validation dataset')\n",
    "    sampler_val = SequentialSampler(dataset_val)\n",
    "    dataloader_val = DataLoader(dataset_val, sampler=sampler_val, batch_size=args.batch_size)\n",
    "\n",
    "    model, optimizer, scheduler = load_optimizer(args, model, len(dataloader_tr), args.learning_rate_tune)\n",
    "\n",
    "    tr_loss = 0.00\n",
    "    num_steps = 0\n",
    "\n",
    "    model.train()\n",
    "    train_iterator = trange(int(args.num_train_epochs), desc=\"Epoch\", disable=False, leave=True, position=1)\n",
    "\n",
    "    for _ in train_iterator:\n",
    "        disable = False\n",
    "        if len(dataloader_tr) > 1000:\n",
    "            disable = True\n",
    "        epoch_iterator = tqdm(dataloader_tr, desc=\"Iteration\", disable=disable, leave=True, position=1)\n",
    "        for step, batch in enumerate(epoch_iterator):\n",
    "\n",
    "            model.train()\n",
    "\n",
    "            batch = tuple(b.to(args.device) for b in batch)\n",
    "            inputs = {'input_ids': batch[0],\n",
    "                      'attention_mask': batch[1],\n",
    "                      'token_type_ids': batch[2] if args.model_type in ['bert', 'xlnet'] else None,\n",
    "                      'labels': batch[3]}\n",
    "\n",
    "            model.zero_grad()\n",
    "            outputs = model(**inputs)\n",
    "            loss = outputs[0]\n",
    "\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "            tr_loss += loss.item()\n",
    "\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            \n",
    "            num_steps += 1\n",
    "\n",
    "            if args.logging_steps_tune > 0 and num_steps % args.logging_steps_tune == 0:\n",
    "                results = evaluate(args, model, dataloader_val)\n",
    "                print(\"\\n val acc: {}, val loss: {}\"\n",
    "                      .format(str(results['val_acc']), str(results['val_loss'])))\n",
    "\n",
    "    loss = tr_loss / num_steps\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def train(args, model, tokenizer):\n",
    "    train_epoch = 1\n",
    "    \n",
    "    processor = ConvEntailProcessor(tokenizer, args)\n",
    "    dataset_tr, lengths_tr = processor.load_features(split='train')\n",
    "    dataset_val, lengths_val = processor.load_features(split='val')\n",
    "\n",
    "    print('\\n Loading training dataset')\n",
    "    sampler_tr = RandomSampler(dataset_tr)\n",
    "    dataloader_tr = DataLoader(dataset_tr, sampler=sampler_tr, batch_size=args.batch_size)\n",
    "\n",
    "    print('\\n Loading validation dataset')\n",
    "    sampler_val = SequentialSampler(dataset_val)\n",
    "    dataloader_val = DataLoader(dataset_val, sampler=sampler_val, batch_size=args.batch_size)\n",
    "\n",
    "    num_steps = 0\n",
    "    best_steps = 0\n",
    "    tr_loss = 0.0\n",
    "    best_val_acc, best_val_loss = 0.0, 99999999999.0\n",
    "    best_model = None\n",
    "\n",
    "    _, optimizer, scheduler = load_optimizer(args, model, len(dataloader_tr), args.learning_rate)\n",
    "\n",
    "    model.train()\n",
    "    train_iterator = trange(int(train_epoch), desc=\"Epoch\", disable=False, leave=True, position=1)\n",
    "\n",
    "    for _ in train_iterator:\n",
    "      epoch_iterator = tqdm(dataloader_tr, desc=\"Iteration\", disable=False, leave=True, position=1)\n",
    "      for step, batch in enumerate(epoch_iterator):\n",
    "\n",
    "          batch = tuple(b.to(args.device) for b in batch)\n",
    "          inputs = {'input_ids': batch[0],\n",
    "                    'attention_mask': batch[1],\n",
    "                    'token_type_ids': batch[2] if args.model_type in ['bert', 'xlnet'] else None,\n",
    "                    'labels': batch[3]}\n",
    "          model.zero_grad()\n",
    "          outputs = model(**inputs)\n",
    "\n",
    "          \n",
    "          loss = outputs[0]\n",
    "\n",
    "          loss.backward()\n",
    "          torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "          tr_loss += loss.item()\n",
    "\n",
    "          optimizer.step()\n",
    "          scheduler.step()\n",
    "          \n",
    "          num_steps += 1\n",
    "\n",
    "          if args.logging_steps > 0 and num_steps % args.logging_steps == 0:\n",
    "              results, tn, fn = evaluate(args, model, dataloader_val, lengths_val)\n",
    "              \n",
    "              print(\"\\n how many 0 is predicted 0: {}, how many 1 is predicted 0: {}, val acc: {}, val loss: {}\"\n",
    "                    .format(str(tn), str(fn), str(results['val_acc']), str(results['val_loss'])))\n",
    "              if results[\"val_loss\"] < best_val_loss:\n",
    "                  best_val_acc, best_val_loss = results[\"val_acc\"], results[\"val_loss\"]\n",
    "                  best_steps = num_steps\n",
    "                  best_model = deepcopy(model)\n",
    "      loss = tr_loss / num_steps\n",
    "      print(loss)\n",
    "\n",
    "    results, tn, fn = evaluate(args, model, dataloader_tr, lengths_tr)\n",
    "    print(\"\\n how many 0 is predicted 0: {}, how many 1 is predicted 0: {}, train acc: {}, train loss: {}\"\n",
    "                      .format(str(tn), str(fn), str(results['val_acc']), str(results['val_loss'])))\n",
    "    print(\"\\n Best val acc: {}, Best val loss: {}\".format(best_val_acc, best_val_loss))\n",
    "\n",
    "    return best_model\n",
    "\n",
    "\n",
    "def evaluate(args, model, dataloader, lengths=None):\n",
    "\n",
    "    val_loss = 0.0\n",
    "    num_steps = 0\n",
    "    preds, labels = None, None\n",
    "\n",
    "    results = {}\n",
    "\n",
    "    for batch in tqdm(dataloader, desc=\"Validation\", disable=True, leave=True, position=1):\n",
    "        model.eval()\n",
    "        batch = tuple(t.to(args.device) for t in batch)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            inputs = {'input_ids': batch[0],\n",
    "                      'attention_mask': batch[1],\n",
    "                      'token_type_ids': batch[2] if args.model_type in ['bert', 'xlnet'] else None,\n",
    "                      'labels': batch[3]}\n",
    "            \n",
    "            outputs = model(**inputs)\n",
    "            logits = outputs[1]\n",
    "\n",
    "            loss = outputs[0]\n",
    " \n",
    "            val_loss += loss.mean().item()\n",
    "\n",
    "        num_steps += 1\n",
    "\n",
    "        if preds is None:\n",
    "            preds = logits.detach().cpu().numpy()\n",
    "            labels = inputs['labels'].detach().cpu().numpy()\n",
    "        else:\n",
    "            preds = np.append(preds, logits.detach().cpu().numpy(), axis=0)\n",
    "            labels = np.append(labels, inputs['labels'].detach().cpu().numpy(), axis=0)\n",
    "\n",
    "    loss = val_loss / num_steps\n",
    "    preds = np.argmax(preds, axis=1)\n",
    "    acc = accuracy_score(preds, labels)\n",
    "    result = {\"val_acc\": acc, \"val_loss\": loss}\n",
    "    results.update(result)\n",
    "\n",
    "    tn, fp, fn, tp = confusion_matrix(labels, preds, normalize='true').ravel()\n",
    "    # classification_report(labels, preds)\n",
    "\n",
    "    return results, tn, fn\n",
    "    # how many 0 is truely predicted 0:tn\n",
    "    # how many 1 is falsely predicted 0:fn\n",
    "\n",
    "\n",
    "def test(args, tokenizer, model):\n",
    "\n",
    "    processor = ConvEntailProcessor(tokenizer, args)\n",
    "    dataset_val, lengths_val = processor.load_features(split='val')\n",
    "    sampler_val = SequentialSampler(dataset_val)\n",
    "    dataloader_val = DataLoader(dataset_val, sampler=sampler_val, batch_size=args.batch_size)\n",
    "    results, tn, fn = evaluate(args, model, dataloader_val, lengths_val)\n",
    "    \n",
    "    print(\"\\n how many 0 is predicted 0: {}, how many 1 is predicted 0: {}, val acc: {}, val loss: {}\"\n",
    "                      .format(str(tn), str(fn), str(results['val_acc']), str(results['val_loss'])))\n",
    "    \n",
    "\n",
    "def test_on_test_dataset(args, tokenizer, model):\n",
    "\n",
    "    processor = ConvEntailProcessor(tokenizer, args)\n",
    "    dataset_test, lengths_test = processor.load_features(split='test')\n",
    "    sampler_test = SequentialSampler(dataset_test)\n",
    "    dataloader_test = DataLoader(dataset_test, sampler=sampler_test, batch_size=args.batch_size)\n",
    "    \n",
    "    val_loss = 0.0\n",
    "    num_steps = 0\n",
    "    preds, labels = None, None\n",
    "\n",
    "    results = {}\n",
    "\n",
    "    for batch in tqdm(dataloader_test, desc=\"Validation\", disable=True, leave=True, position=1):\n",
    "        model.eval()\n",
    "        batch = tuple(t.to(args.device) for t in batch)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            inputs = {'input_ids': batch[0],\n",
    "                      'attention_mask': batch[1],\n",
    "                      'token_type_ids': batch[2] if args.model_type in ['bert', 'xlnet'] else None,\n",
    "                      'labels': None}\n",
    "            \n",
    "            outputs = model(**inputs)\n",
    "            logits = outputs[1]\n",
    "\n",
    "        num_steps += 1\n",
    "\n",
    "        if preds is None:\n",
    "            preds = logits.detach().cpu().numpy()\n",
    "        else:\n",
    "            preds = np.append(preds, logits.detach().cpu().numpy(), axis=0)\n",
    "\n",
    "\n",
    "    preds = np.argmax(preds, axis=1)\n",
    "    out = preds.tolist()\n",
    "    out_file = open(\"/content/ConvEnt_team2_preds.json\", 'w')\n",
    "    json.dump(out, out_file)\n",
    "    out_file.close()\n",
    "    \n",
    "    print(\"Test over. File should have been written.\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Nyv6xGVDhfEZ"
   },
   "source": [
    "def main(args):\n",
    "    print('Using device', args.device)\n",
    "    print('Using model', args.model_type)\n",
    "    set_seed(args.seed)\n",
    "\n",
    "    num_labels = 2\n",
    "\n",
    "    config = AutoConfig.from_pretrained(args.model_name)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(args.model_name)\n",
    "    \n",
    "    pretrained_model = AutoModelForSequenceClassification.from_pretrained(args.model_name)\n",
    "    # model = MyBertClassifier(model_name=args.config_name, num_labels=1)\n",
    "    # model = MyRobertaClassifier()\n",
    "    model = myRoberta_mnliClassifier(pretrained_model)\n",
    "\n",
    "    model.to(args.device)\n",
    "\n",
    "    print('\\nTuning...')\n",
    "    #model = fine_tune(args, model, tokenizer)\n",
    "    # model = freeze(model, args.model_name)\n",
    "\n",
    "    print('\\nTraining...')\n",
    "    best_model = train(args, model, tokenizer)\n",
    "\n",
    "    print('\\nTesting...')\n",
    "    test_on_test_dataset(args, tokenizer, best_model)\n",
    "\n",
    "    return best_model"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qGOc8j4Hz7OC"
   },
   "source": [
    "The default model is based on `bert`, and\n",
    "```\n",
    "parser.add_argument(\"--model_name\", type=str, default='bert-base-uncased',\n",
    "                    help=\"Path to pre-trained model or shortcut name. See https://huggingface.co/models\")\n",
    "```\n",
    "\n",
    "This would leads to\n",
    "\n",
    "```\n",
    "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMultipleChoice: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
    "- This IS expected if you are initializing BertForMultipleChoice from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
    "- This IS NOT expected if you are initializing BertForMultipleChoice from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
    "Some weights of BertForMultipleChoice were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
    "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
    "Using custom data configuration default\n",
    "```\n",
    "\n",
    "Should check https://huggingface.co/models for other models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VfotIM0w1oX-"
   },
   "source": [
    "Setup parameters."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "W_F0_crozIjr"
   },
   "source": [
    "def run(model_type='bert',\n",
    "        model_name='bert-base-uncased',\n",
    "        task_name=None,\n",
    "        batch_size=64,\n",
    "        lr=1e-5,\n",
    "        lr_tune=1e-5,\n",
    "        epochs=1,\n",
    "        pretrain_size=1000,\n",
    "        logging_steps=50,\n",
    "        logging_steps_tune=200):\n",
    "  \n",
    "    parser = argparse.ArgumentParser(description=\"Common sense question answering\")\n",
    "    parser.add_argument(\"--model_type\", type=str, default=model_type,\n",
    "                        help=\"Model: <str> [ bert | xlnet | roberta | gpt2 ]\")\n",
    "    parser.add_argument(\"--task_name\", default=task_name, type=str, required=False,\n",
    "                        help=\"The name of the task to train: <str> [ commonqa ]\")\n",
    "    parser.add_argument(\"--model_name\", type=str,\n",
    "                        default=model_name,\n",
    "                        help=\"Path to pre-trained model or shortcut name.\"\n",
    "                              \"See https://huggingface.co/models\")\n",
    "    parser.add_argument(\"--config_name\", type=str,\n",
    "                        default=model_name,\n",
    "                        help=\"Pre-trained config name or path\")\n",
    "    parser.add_argument(\"--tokenizer_name\", default=model_name, type=str,\n",
    "                        help=\"Pre-trained tokenizer name or path if not the same as model_name\")\n",
    "\n",
    "    parser.add_argument(\"--max_seq_length\", default=100, type=int,\n",
    "                        help=\"The maximum total input sequence length after tokenization. \"\n",
    "                                \"Sequences longer than this will be truncated, sequences shorter will be padded.\")\n",
    "    parser.add_argument(\"--batch_size\", default=batch_size, type=int,\n",
    "                        help=\"Batch size for training.\")\n",
    "\n",
    "    parser.add_argument(\"--learning_rate\", default=lr, type=float,\n",
    "                        help=\"The initial learning rate for Adam.\")\n",
    "    parser.add_argument(\"--learning_rate_tune\", default=lr_tune, type=float,\n",
    "                        help=\"The initial learning rate for Adam.\")\n",
    "    parser.add_argument(\"--weight_decay\", default=0.0, type=float,\n",
    "                        help=\"Weight decay if we apply some.\")\n",
    "    parser.add_argument(\"--adam_epsilon\", default=1e-8, type=float,\n",
    "                        help=\"Epsilon for Adam optimizer.\")\n",
    "    parser.add_argument(\"--test_size\", default=0.2, type=float,\n",
    "                        help=\"The ratio of size of validation set\")\n",
    "    parser.add_argument(\"--pretrain_size\", default=pretrain_size, type=float,\n",
    "                        help=\"The ratio of size of validation set\")\n",
    "        \n",
    "    parser.add_argument(\"--num_train_epochs\", default=epochs, type=int,\n",
    "                        help=\"Total number of training epochs to perform.\")\n",
    "    parser.add_argument(\"--warmup_steps\", default=epochs//6+2, type=int,\n",
    "                        help=\"Linear warmup over warmup_steps.\")\n",
    "    parser.add_argument('--logging_steps', type=int, default=logging_steps,\n",
    "                        help=\"Log every n updates steps.\")\n",
    "    parser.add_argument('--logging_steps_tune', type=int, default=logging_steps_tune,\n",
    "                        help=\"Log every n updates steps.\")\n",
    "\n",
    "    parser.add_argument('--fp16', type=bool, default=True,\n",
    "                        help=\"Whether to use 16-bit (mixed) precision (through NVIDIA apex) instead of 32-bit\")\n",
    "    parser.add_argument('--opt_level', type=str, default='O1',\n",
    "                        help=\"For fp16: Apex AMP optimization level selected in ['O0', 'O1', 'O2', and 'O3'].\"\n",
    "                              \"See details at https://nvidia.github.io/apex/amp.html\")\n",
    "\n",
    "    parser.add_argument(\"--seed\", type=int, default=0, help=\"Random seed: <int>\")\n",
    "    parser.add_argument(\"--device\", default=DEVICE)\n",
    "    args, unknown = parser.parse_known_args()\n",
    "    best_model = main(args)\n",
    "    return best_model"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NmE312LRWvvR"
   },
   "source": [
    "## Finetuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2GJvvByG0O-j"
   },
   "source": [
    "### RoBerta\n",
    "\n",
    "Check this for `</s>` rules: https://github.com/pytorch/fairseq/issues/1654\n",
    "\n",
    "I may have got it wrong. Check `Data Preprocessing` sections."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Om27bZcK1pUx"
   },
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9rprO1FhzIJj"
   },
   "source": [
    "Try `roberta-large-mnli`, but this one has a `neutral` label (`num_labels = 3`).\n",
    "\n",
    "There is an [online entailment](https://huggingface.co/roberta-large-mnli?text=John+grabbed+the+ladder+and+put+it+in+his+truck.+%3C%2Fs%3E%3C%2Fs%3E+John+put+a+drill+and+rope+in+the+bucket+and+also+put+that+in+this+truck) model to play with."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "A29iZ1dduQHK",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "a50ba813-df45-40e0-d022-29a04c4ea754"
   },
   "source": [
    "# Try roberta-large-mnli\n",
    "model_type = 'roberta'\n",
    "model_name = 'roberta-large-mnli'\n",
    "task_name = 'mnli'\n",
    "batch_size = 8\n",
    "epochs = 1\n",
    "lr_tune = 1e-6\n",
    "lr = 5e-6\n",
    "# pretrain_size = 73546\n",
    "pretrain_size = 50\n",
    "logging_steps = 25\n",
    "logging_steps_tune = 50\n",
    "\n",
    "best_model = run(model_type, model_name, task_name, batch_size, lr, lr_tune, epochs, pretrain_size, logging_steps, logging_steps_tune)"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Using device cuda\n",
      "Using model roberta\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-large-mnli were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ],
     "name": "stderr"
    },
    {
     "output_type": "stream",
     "text": [
      "\n",
      "Tuning...\n",
      "\n",
      "Training...\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Iteration:   0%|          | 0/52 [00:00<?, ?it/s]\u001b[A"
     ],
     "name": "stderr"
    },
    {
     "output_type": "stream",
     "text": [
      "\n",
      " Loading training dataset\n",
      "\n",
      " Loading validation dataset\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:   2%|▏         | 1/52 [00:01<00:54,  1.08s/it]\u001b[A\n",
      "Iteration:   4%|▍         | 2/52 [00:02<00:53,  1.06s/it]\u001b[A\n",
      "Iteration:   6%|▌         | 3/52 [00:03<00:52,  1.07s/it]\u001b[A\n",
      "Iteration:   8%|▊         | 4/52 [00:04<00:51,  1.06s/it]\u001b[A\n",
      "Iteration:  10%|▉         | 5/52 [00:05<00:50,  1.06s/it]\u001b[A\n",
      "Iteration:  12%|█▏        | 6/52 [00:06<00:49,  1.07s/it]\u001b[A\n",
      "Iteration:  13%|█▎        | 7/52 [00:07<00:47,  1.07s/it]\u001b[A\n",
      "Iteration:  15%|█▌        | 8/52 [00:08<00:46,  1.07s/it]\u001b[A\n",
      "Iteration:  17%|█▋        | 9/52 [00:09<00:45,  1.07s/it]\u001b[A\n",
      "Iteration:  19%|█▉        | 10/52 [00:10<00:45,  1.08s/it]\u001b[A\n",
      "Iteration:  21%|██        | 11/52 [00:11<00:44,  1.09s/it]\u001b[A\n",
      "Iteration:  23%|██▎       | 12/52 [00:12<00:43,  1.09s/it]\u001b[A\n",
      "Iteration:  25%|██▌       | 13/52 [00:13<00:42,  1.09s/it]\u001b[A\n",
      "Iteration:  27%|██▋       | 14/52 [00:15<00:41,  1.09s/it]\u001b[A\n",
      "Iteration:  29%|██▉       | 15/52 [00:16<00:40,  1.09s/it]\u001b[A\n",
      "Iteration:  31%|███       | 16/52 [00:17<00:39,  1.09s/it]\u001b[A\n",
      "Iteration:  33%|███▎      | 17/52 [00:18<00:38,  1.09s/it]\u001b[A\n",
      "Iteration:  35%|███▍      | 18/52 [00:19<00:37,  1.09s/it]\u001b[A\n",
      "Iteration:  37%|███▋      | 19/52 [00:20<00:36,  1.09s/it]\u001b[A\n",
      "Iteration:  38%|███▊      | 20/52 [00:21<00:34,  1.09s/it]\u001b[A\n",
      "Iteration:  40%|████      | 21/52 [00:22<00:33,  1.10s/it]\u001b[A\n",
      "Iteration:  42%|████▏     | 22/52 [00:23<00:33,  1.10s/it]\u001b[A\n",
      "Iteration:  44%|████▍     | 23/52 [00:24<00:32,  1.11s/it]\u001b[A\n",
      "Iteration:  46%|████▌     | 24/52 [00:26<00:31,  1.11s/it]\u001b[A\n",
      "Iteration:  48%|████▊     | 25/52 [00:32<01:10,  2.60s/it]\u001b[A"
     ],
     "name": "stderr"
    },
    {
     "output_type": "stream",
     "text": [
      "\n",
      " how many 0 is predicted 0: 0.5106382978723404, how many 1 is predicted 0: 0.2631578947368421, val acc: 0.6346153846153846, val loss: 0.6519540892197535\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  50%|█████     | 26/52 [00:33<00:56,  2.16s/it]\u001b[A\n",
      "Iteration:  52%|█████▏    | 27/52 [00:34<00:46,  1.85s/it]\u001b[A\n",
      "Iteration:  54%|█████▍    | 28/52 [00:35<00:39,  1.64s/it]\u001b[A\n",
      "Iteration:  56%|█████▌    | 29/52 [00:36<00:34,  1.49s/it]\u001b[A\n",
      "Iteration:  58%|█████▊    | 30/52 [00:37<00:30,  1.38s/it]\u001b[A\n",
      "Iteration:  60%|█████▉    | 31/52 [00:38<00:27,  1.31s/it]\u001b[A\n",
      "Iteration:  62%|██████▏   | 32/52 [00:40<00:25,  1.26s/it]\u001b[A\n",
      "Iteration:  63%|██████▎   | 33/52 [00:41<00:23,  1.23s/it]\u001b[A\n",
      "Iteration:  65%|██████▌   | 34/52 [00:42<00:21,  1.21s/it]\u001b[A\n",
      "Iteration:  67%|██████▋   | 35/52 [00:43<00:20,  1.20s/it]\u001b[A\n",
      "Iteration:  69%|██████▉   | 36/52 [00:44<00:18,  1.18s/it]\u001b[A\n",
      "Iteration:  71%|███████   | 37/52 [00:45<00:17,  1.17s/it]\u001b[A\n",
      "Iteration:  73%|███████▎  | 38/52 [00:47<00:16,  1.16s/it]\u001b[A\n",
      "Iteration:  75%|███████▌  | 39/52 [00:48<00:15,  1.16s/it]\u001b[A\n",
      "Iteration:  77%|███████▋  | 40/52 [00:49<00:13,  1.16s/it]\u001b[A\n",
      "Iteration:  79%|███████▉  | 41/52 [00:50<00:12,  1.15s/it]\u001b[A\n",
      "Iteration:  81%|████████  | 42/52 [00:51<00:11,  1.14s/it]\u001b[A\n",
      "Iteration:  83%|████████▎ | 43/52 [00:52<00:10,  1.14s/it]\u001b[A\n",
      "Iteration:  85%|████████▍ | 44/52 [00:53<00:09,  1.13s/it]\u001b[A\n",
      "Iteration:  87%|████████▋ | 45/52 [00:54<00:07,  1.13s/it]\u001b[A\n",
      "Iteration:  88%|████████▊ | 46/52 [00:56<00:06,  1.12s/it]\u001b[A\n",
      "Iteration:  90%|█████████ | 47/52 [00:57<00:05,  1.12s/it]\u001b[A\n",
      "Iteration:  92%|█████████▏| 48/52 [00:58<00:04,  1.12s/it]\u001b[A\n",
      "Iteration:  94%|█████████▍| 49/52 [00:59<00:03,  1.12s/it]\u001b[A\n",
      "Iteration:  96%|█████████▌| 50/52 [01:05<00:05,  2.57s/it]\u001b[A"
     ],
     "name": "stderr"
    },
    {
     "output_type": "stream",
     "text": [
      "\n",
      " how many 0 is predicted 0: 0.574468085106383, how many 1 is predicted 0: 0.2631578947368421, val acc: 0.6634615384615384, val loss: 0.6281949694340045\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  98%|█████████▊| 51/52 [01:06<00:02,  2.12s/it]\u001b[A\n",
      "Iteration: 100%|██████████| 52/52 [01:07<00:00,  1.30s/it]\n",
      "\n",
      "Epoch: 100%|██████████| 1/1 [01:07<00:00, 67.53s/it]\n"
     ],
     "name": "stderr"
    },
    {
     "output_type": "stream",
     "text": [
      "0.6233969749166415\n",
      "\n",
      " how many 0 is predicted 0: 0.7015706806282722, how many 1 is predicted 0: 0.13777777777777778, train acc: 0.7884615384615384, train loss: 0.4386906801508023\n",
      "\n",
      " Best val acc: 0.6634615384615384, Best val loss: 0.6281949694340045\n",
      "\n",
      "Testing...\n",
      "Test over. File should have been written.\n"
     ],
     "name": "stdout"
    }
   ]
  }
 ]
}